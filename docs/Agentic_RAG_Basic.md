# 목차

- [Chapter 1: LLM 한계에서 RAG·Agentic까지 (기초)](#chapter-1)
  - [1.0 RAG가 이미 쓰이는 곳 : 실전 사례로 먼저 감 잡기](#sec-1-0)
  - [1.1 LLM을 실무에 붙일 때 터지는 4가지 한계](#sec-1-1)
  - [1.2 RAG: 정의, 파이프라인, 그리고 Agentic RAG로의 로드맵](#sec-1-2)
    - [1.2.1 RAG 한 줄 정의](#sec-1-2-1)
    - [1.2.2 RAG의 기본 흐름(한 줄 요약)](#sec-1-2-2)
    - [1.2.3 왜 Agentic RAG로 넘어가나요?](#sec-1-2-3)
  - [1.3 텍스트를 숫자로 : 벡터 표현의 이해](#sec-1-3)
  - [1.4 청킹(Chunking) 전략: 컨텍스트 윈도우 제한을 "검색 가능한 형태"로 바꾸기](#sec-1-4)
    - [1.4.1 청킹 한 줄 정의](#sec-1-4-1)
    - [1.4.2 청킹의 목적](#sec-1-4-2)
    - [1.4.3 감 잡는 기본값(실무 출발점)](#sec-1-4-3)
    - [1.4.4 주요 청킹 전략(3가지)](#sec-1-4-4)
    - [1.4.5 청킹 전략을 고르는 기준(실무 체크리스트)](#sec-1-4-5)
    - [1.4.6 실제 프로젝트에서의 접근법(실험 기반)](#sec-1-4-6)
    - [1.4.7 실전 팁(바로 적용 가능한 가이드)](#sec-1-4-7)
  - [1.5 RAG 시스템의 구조와 작동 원리](#sec-1-5)
  - [2.2 RAG가 해결하는 LLM의 핵심 문제점](#sec-2-2)
    - [실전 활용 예시: 기업 내부 문서 Q&A 시스템](#sec-2-2-example)
  - [2.3 LangChain 프레임워크: RAG 구현을 “빠르게” 돕는 도구(장단점 포함)](#sec-2-3)
    - [2.3.1 LangChain이란?](#sec-2-3-1)
    - [2.3.2 LangChain이 해결하는 문제](#sec-2-3-2)
    - [2.3.3 순수 구현 vs LangChain 비교](#sec-2-3-3)
    - [2.3.4 LangChain의 장점과 한계](#sec-2-3-4)
    - [2.3.5 실무 의사결정 가이드](#sec-2-3-5)
- [Chapter 3: RAG 고급 기법과 Agentic RAG로의 전환](#chapter-3)
  - [3.1 RAG 검색 최적화 기법: 정확도를 높이는 고급 전략](#sec-3-1)
    - [3.1.1 하이브리드 검색 (Hybrid Search): 의미와 키워드의 조화](#sec-3-1-1)
    - [3.1.2 Re-ranking (재정렬): 2단계 정밀 검색](#sec-3-1-2)
    - [3.1.3 Multi-hop Reasoning (다단계 추론): 복잡한 질문 해결](#sec-3-1-3)
  - [3.2 Agentic RAG로의 전환: 정적 파이프라인을 넘어서](#sec-3-2)
    - [3.2.1 AI 에이전트 : 스스로 일하는 '디지털 비서'](#sec-3-2-1)
    - [3.2.2 기존 RAG의 한계와 Agentic RAG의 필요성](#sec-3-2-2)
    - [3.2.3 Tool-using Agent 설계 패턴](#sec-3-2-3)
    - [3.2.4 기존 RAG vs Agentic RAG 비교 (최종 정리)](#sec-3-2-4)
  - [3.3 Multi-Agent: '어벤져스 팀'처럼 협력하는 AI들](#sec-3-3)
    - [멀티 에이전트 시스템의 아키텍처](#sec-3-3-arch)
    - [멀티 에이전트의 장점과 과제](#sec-3-3-pros-cons)
  - [3.4 Master Agent vs Specialized Agents](#sec-3-4)
  - [3.5 Function Calling 구현 패턴](#sec-3-5)
  - [3.6 프롬프트 엔지니어링 실전](#sec-3-6)
- [Chapter 4: Agentic RAG 실전 구현 (코드 중심)](#chapter-4)
  - [4.1 구현 아키텍처 개요](#sec-4-1)
    - [시스템 구성도](#sec-4-1-diagram)
    - [핵심 컴포넌트](#sec-4-1-components)
  - [4.2 각 에이전트 상세 분석](#sec-4-2)
    - [4.2.1 ChatService (Master Agent) (`services/chat_service.py`)](#sec-4-2-1)
    - [4.2.2 IntentClassifier Agent (`agents/intent_classifier.py`)](#sec-4-2-2)
    - [4.2.3 TaskPlannerAgent (`agents/task_planner_agent.py`)](#sec-4-2-3)
    - [4.2.4 ToolExecutor (`services/tool_executor.py`)](#sec-4-2-4)
  - [4.3 Multi-Agent 실행 흐름 Deep Dive](#sec-4-3)
    - [Step 1: IntentClassifier (의도 분류)](#sec-4-3-step-1)
    - [Step 2: TaskPlannerAgent (계획 수립)](#sec-4-3-step-2)
    - [Step 3: ToolExecutor (실행 및 관찰)](#sec-4-3-step-3)
    - [Step 4: ChatService (최종 답변 종합)](#sec-4-3-step-4)
    - [핵심 인사이트](#sec-4-3-insights)
  - [4.4 코드 리뷰: 주요 구현 포인트](#sec-4-4)
    - [4.4.1 벡터 DB 연결 및 RAG 도구 구성](#sec-4-4-1)
    - [4.4.2 에이전트 생성 및 실행](#sec-4-4-2)
- [Chapter 5: 실전 활용 및 최적화](#chapter-5)
  - [5.1 성능 최적화 전략](#sec-5-1)
    - [5.1.1 LLM 토큰 비용 관리](#sec-5-1-1)
    - [5.1.2 응답 속도 향상](#sec-5-1-2)
    - [5.1.3 검색 품질 개선](#sec-5-1-3)
    - [추천 리소스](#sec-5-1-resources)

---

<a id="chapter-1"></a>

# Chapter 1: LLM 한계에서 RAG·Agentic까지 (기초)

<a id="sec-1-0"></a>

## 1.0 RAG가 이미 쓰이는 곳 : 실전 사례로 먼저 감 잡기

RAG는 “이론”이 아니라, 이미 많은 제품/서비스에서 **사용자의 신뢰를 확보하기 위한 기본 장치**로 쓰이고 있습니다.  
여기서는 대표적인 사례를 보고, “왜 LLM만으로는 부족한가?”를 직관적으로 잡고 들어가겠습니다.

> 많은 분들이 RAG 자체는 이미 익숙하지만, 막상 비즈니스에 붙여보면 “**정확도**”가 가장 먼저 병목이 됩니다.  
> 그래서 실무에서는 Re-ranking 같은 고급 검색 기법을 더하고, 나아가 **Agentic RAG / Graph RAG**처럼 여러 구성요소를 **복합 구조로** 엮는 방향으로 진화하고 있습니다.  
> 이 강의는 그중에서도 **Agentic RAG가 무엇이고, 어떻게 구현하는지**를 “가볍게 시작해서 실제로 동작까지” 이해시키는 데 초점을 둡니다.

- **Perplexity(유형 예시: 웹 기반 답변 엔진)**
  - 특징: 답변에 **출처/링크를 같이 제시**하며, 질문에 따라 웹 문서를 찾아 근거를 붙이는 흐름이 자연스럽습니다.
  - 강의 포인트: “LLM이 말하기 전에 **찾아보고** 말하게 만들면 신뢰가 올라간다.”

- **Cursor(유형 예시: 코드 에디터 + AI)**
  - 특징: 내 코드베이스를 맥락으로 삼아 **관련 파일/코드 조각을 찾아** 답변하거나 수정 제안을 합니다.
  - 강의 포인트: RAG의 정보 소스는 웹뿐 아니라 **사내 문서/코드/DB**도 될 수 있다.

- **Claude Projects(유형 예시: 프로젝트 단위 지식/컨텍스트)**
  - 특징: 프로젝트에 문서를 넣어두고, 그 범위 안에서 **일관된 맥락**으로 답변을 유도합니다.
  - 강의 포인트: “지식을 모델에 ‘학습’시키는 게 아니라, **참조 가능한 형태로 연결**하는 설계가 중요하다.”

> 한 줄 정리: RAG는 “답변 능력”을 키우는 게 아니라, 답변의 **근거와 최신성**을 확보하는 쪽에 가깝습니다.

---

<a id="sec-1-1"></a>

## 1.1 LLM을 실무에 붙일 때 터지는 4가지 한계


이 섹션에서는 Agentic RAG로 들어가기 전에, LLM을 실무에 붙일 때 가장 먼저 마주치는 **“신뢰성 문제”**를 짚습니다.  
LLM은 똑똑해 보이지만 **근거 없이도 그럴듯하게 말할 수 있고**, **최신 정보/긴 문맥**에서도 분명한 제약이 있습니다.

그래서 여기서는 **가장 자주 터지는 문제인 “환각(Hallucination)”부터** 이해하고, 그 다음에 “근거를 가져오게 만드는 방식”인 RAG로 자연스럽게 연결합니다.

> 미리 한 줄만 : **RAG는 답하기 전에 관련 문서를 찾아(검색) 그 근거로 답하게 만드는 방식**입니다.

**왜 이게 중요할까요?** 아래 4가지 한계가 실무에서 특히 치명적으로 드러나기 때문입니다.

**1) 환각(Hallucination) - 그럴듯한 거짓 정보 생성**

- **현상** : LLM은 학습하지 않은 내용도 마치 사실처럼 생성
- **원인** : 확률 기반 텍스트 생성 메커니즘
  - LLM은 "다음 단어를 확률적으로 예측"하는 방식으로 작동
  - 학습 데이터에 없는 내용도 통계적으로 그럴듯한 조합으로 생성 가능
- **예시** : "세종대왕이 맥북을 사용했다"는 질문에도 그럴듯한 허구 생성
- **실무에서 이렇게 터집니다**
  - 정책/약관/사내 규정 같은 “정답이 정해진 문서” 질문에서, **문서에 없는 조항을 만들어내는** 형태로 많이 발생
  - 숫자/기간/예외조건(“~인 경우에만”)을 **자신감 있게** 말하는 게 특히 위험
- **RAG 관점의 포인트**
  - 검색된 문서 조각을 함께 주면, 답변이 **문서 근거로 수렴**할 확률이 커짐
  - 단, “검색이 틀리면 답도 틀린다”는 점은 반드시 기억해야 함(= Garbage In, Garbage Out)

**2) Knowledge Cut-off - 학습 시점 이후 정보 부재**

- **현상** : 특정 시점 이후의 정보를 전혀 알지 못함
- **원인** : Pre-training 데이터의 시간적 한계
  - Claude 4.5 : 2025년 1월까지의 데이터로 학습
- **예시** : "2025년 하반기에 출시된 파이썬 라이브러리 정보"에 대해 알지 못함
- **실무에서 이렇게 보입니다**
  - 최신 릴리즈 노트, 신규 정책 변경, 방금 업데이트된 사내 위키 같은 “최근 정보” 질문에 취약
  - 특히 “방금 배포된 기능”은 모델이 절대 알 수 없음
- **RAG 관점의 포인트**
  - 지식베이스(문서/DB)를 최신으로 유지하면, 모델이 업데이트되지 않아도 **최신 정보로 답변** 가능
  - 그래서 RAG는 모델을 자주 재학습시키는 대신, **지식(데이터)을 운영**하는 접근에 가깝습니다.

**3) Lost in the Middle - 긴 컨텍스트 중간 정보 망각**

- **현상** : 긴 문서를 읽을 때 처음과 끝은 잘 기억하지만, 중간 내용은 놓침
- **원인** : Attention 메커니즘의 한계
  - 컨텍스트가 길어질수록 중간 정보에 대한 가중치 감소
  - U자형 망각 곡선 : 사람의 기억력과 유사한 패턴
- **RAG 영향** : 검색 결과를 어떤 순서로 배치하느냐가 성능에 직접 영향
  - 중요한 정보는 프롬프트의 처음이나 끝에 배치하는 전략 필요
- **초보자에게 중요한 한 줄**
  - “문서를 많이 주면 더 똑똑해진다”가 아니라, 오히려 **중요한 부분만 잘 추려서** 주는 게 성능에 더 중요할 때가 많습니다.

**4) 컨텍스트 윈도우(Context Window) 제한**

- **컨텍스트란?** : LLM에 입력하는 모든 텍스트
  - 시스템 프롬프트 + 대화 이력 + 사용자 질문 + 검색된 문서 등
- **현상** : LLM이 한 번에 처리할 수 있는 텍스트 양에 물리적 한계 존재
- **모델별 제한**
  - GPT-4 Turbo : 128K 토큰(~10만 단어)
  - Claude 3.5 Sonnet : 200K 토큰(~15만 단어)
  - GPT-3.5 : 16K 토큰(~1.2만 단어)
- **문제** : 백과사전이나 대규모 문서를 통째로 입력할 수 없음
- **컨텍스트를 박스로 보면 이해가 쉽습니다**

```text
[컨텍스트 전체]
┌───────────────────────────────────────────┐
│ System: 모델의 역할/제약(규칙)             │
├───────────────────────────────────────────┤
│ Conversation: 이전 대화(기억처럼 보이는 것) │
├───────────────────────────────────────────┤
│ User: 현재 질문                            │
├───────────────────────────────────────────┤
│ Retrieved Docs: 검색된 문서 조각(근거)       │
└───────────────────────────────────────────┘
```

- **토큰(Token) 주의**
  - 많은 API는 **토큰 단위로 과금**되며, 컨텍스트가 길수록 비용/지연이 증가
  - 그래서 RAG에서는 “관련 문서 Top-K를 무작정 많이 넣기”보다, **적게 넣되 잘 넣는 것**이 핵심

- **LLM API 호출 주의**
  - LLM API 호출은 보통 **요청 1회 = 응답 1회**라서, “대화가 이어지는 것”처럼 보이려면 **이전 대화/상태를 매번 컨텍스트로 다시 넣는 설계**가 필요합니다.
  - 대화형 RAG에서는 **(1) 어떤 대화 이력을 유지/삭제할지**, **(2) 길어지면 어떻게 요약할지**, **(3) 사용자별 상태(세션/메모리)를 어디에 저장할지**가 품질과 비용을 좌우합니다.
  - Agentic RAG에서는 여기에 더해 **도구 호출 결과/중간 결론(작업 메모)**까지 상태로 관리하고, 검색도 “현재 질문”뿐 아니라 **대화 맥락을 반영해 쿼리를 재작성/확장**하는 흐름을 고려합니다.


<a id="sec-1-2"></a>

## 1.2 RAG: 정의, 파이프라인, 그리고 Agentic RAG로의 로드맵

<a id="sec-1-2-1"></a>

### 1.2.1 RAG 한 줄 정의

- LLM이 답변을 만들기 전에, **외부 지식(문서/DB/위키/사내 매뉴얼 등)에서 관련 정보를 검색(Retrieval)**하고 그 내용을 **근거로 답변을 생성(Generation)**하는 방식
- 핵심은 “모델이 혼자 기억으로 말하게 두지 말고, **근거를 가져오게 만들자(grounding)**” 입니다.

<a id="sec-1-2-2"></a>

### 1.2.2 RAG의 기본 흐름(한 줄 요약)

```text
질문 → (검색) 관련 문서 조각 Top-K → (정리/압축) → (생성) 근거 기반 답변 + 출처
```

> **RAG는 이러한 한계를 어떻게 개선하는가?**
>
> - **환각 완화** : 외부 문서를 근거로 제시(단, 검색 품질에 의존)
> - **최신 정보 제공** : 지식베이스 업데이트로 해결(단, 수동 관리 필요)
> - **컨텍스트 효율화** : 필요한 부분만 검색하여 제공
> - **출처 명시** : 답변의 근거가 되는 원본 문서 제시 가능
>
> ※ RAG도 완벽한 해결책은 아니며, 검색 품질과 지식베이스 관리가 핵심입니다

<a id="sec-1-2-3"></a>

### 1.2.3 왜 Agentic RAG로 넘어가나요?

기본 RAG의 한계
* 기본 RAG는 "질문 → 검색 → 답변"이라는 단순한 선형 흐름을 따릅니다.
* 하지만 실제 업무 환경에서는 이런 단순 흐름만으로는 부족한 경우가 많습니다.

복잡한 질문이 요구하는 것들
1. **질문 명확화**: "최근 실적이 어때?"처럼 애매한 질문을 만나면
   - 어느 기간? 어느 부서? 어떤 지표?
   - 되묻고, 확인하고, 명확히 해야 합니다

2. **검색 전략 조정**: 첫 검색에서 관련 문서를 못 찾으면
   - 검색어를 바꿔보거나
   - 다른 데이터 소스를 시도하거나
   - 검색 범위를 조정해야 합니다

3. **다단계 추론**: 단순 검색만으로는 답을 못 내는 경우
   - 여러 문서를 비교/검증하거나
   - 계산이나 외부 도구 호출이 필요하거나
   - 중간 결과를 바탕으로 추가 검색이 필요합니다

Agentic RAG의 핵심
* **자율적 판단**: "다음에 뭘 해야 할지" 스스로 결정
* **반복적 개선**: 결과가 부족하면 전략을 바꿔 재시도
* **도구 활용**: 검색 외에도 필요한 도구(계산기, API, DB 등)를 선택적으로 사용

즉, Agentic RAG는 "한 번에 끝나는 RAG"가 아니라 "문제를 풀 때까지 계속 행동하는 RAG"입니다.

---

<a id="sec-1-4"></a>

## 1.4 청킹(Chunking) 전략: 컨텍스트 윈도우 제한을 "검색 가능한 형태"로 바꾸기

컨텍스트 윈도우에는 물리적인 한계가 있으니, 10페이지짜리 문서를 **그대로 통째로** LLM에게 던지면 보통 이런 문제가 생깁니다.

- **토큰 한도 초과**로 아예 입력이 안 되거나
- 들어가더라도 **중요한 내용이 중간에서 묻히는**(Lost in the Middle) 현상이 생기거나
- 비용/지연이 폭증합니다.

그래서 RAG는 문서를 그대로 “읽히게” 하는 게 아니라, 문서를 “찾아 쓸 수 있게” 바꾸는 전처리부터 시작합니다. 그 핵심이 **청킹(Chunking)**입니다.

<a id="sec-1-4-1"></a>

### 1.4.1 청킹 한 줄 정의

- 긴 문서를 LLM이 다루기 좋은 크기의 텍스트 조각(Chunk)으로 나누고, 각 조각에 **출처/위치/제목 같은 메타데이터**를 붙여서 나중에 **검색 → 인용 → 근거 제시**가 가능하게 만드는 전처리입니다.

<a id="sec-1-4-2"></a>

### 1.4.2 청킹의 목적

- **검색 품질**: “질문에 답이 들어있는 부분”이 한 덩어리로 잡히도록
- **컨텍스트 효율**: 필요한 조각만 넣어서 토큰을 아끼도록
- **인용 가능성**: 출처/페이지/섹션을 붙여서 나중에 “어디 근거냐?”를 말할 수 있도록

<a id="sec-1-4-3"></a>

### 1.4.3 감 잡는 기본값(실무 출발점)

- Chunk size: **300~800 tokens**
- Overlap: **10~20%** (문맥 단절 완화)
- 규칙: “**한 청크 = 한 주제**”가 되도록(문단/헤딩 경계 존중)

#### 오버랩(Overlap) 예시

```
청크 1: [문장A 문장B 문장C]
청크 2:              [문장C 문장D 문장E]
                     ↑ 오버랩 영역
```

<a id="sec-1-4-4"></a>

### 1.4.4 주요 청킹 전략(3가지)

- **Fixed-size Chunking**
  - 고정된 크기로 텍스트를 자름
  - 장점 : 구현이 간단함
  - 단점 : 문장의 의미가 중간에 잘릴 위험

- **Recursive Character Text Splitting**
  - 재귀적으로 문단 → 문장 순으로 분할
  - 의미 경계를 최대한 존중하며 분할

- **Semantic Chunking**
  - 임베딩 모델을 사용하여 의미적으로 유사한 문장들을 하나의 청크로 묶음
  - 가장 진보된 방식 (다만 비용/복잡도 증가)

<a id="sec-1-4-5"></a>

### 1.4.5 청킹 전략을 고르는 기준(실무 체크리스트)

청킹은 “어떤 알고리즘이 더 좋아?”의 문제가 아니라, **우리 데이터/질문/비용 제약**에 맞춰 의사결정하는 문제입니다. 아래 기준으로 먼저 상황을 정리하세요.

| 기준             | 의미                       | 예시                    |
|------------------|----------------------------|-------------------------|
| **데이터 구조**   | 문서의 구조화 정도         | 표, 목록, 연속 텍스트   |
| **질문 유형**     | 예상되는 질문의 복잡성     | 단순 검색, 다단계 추론  |
| **성능 요구**     | 응답 시간, 정확도 요구사항 | 실시간 vs 배치 처리     |
| **비용 제약**     | 저장 공간, 처리 비용       | 클라우드 vs 온프레미스  |
| **업데이트 빈도** | 데이터 변경 주기           | 정적 vs 동적 데이터     |

> 핵심 메시지: 청킹은 “길이를 줄이는 트릭”이 아니라, 문서를 **검색/인용 가능한 구조**로 바꾸는 설계입니다.

<a id="sec-1-4-6"></a>

### 1.4.6 실제 프로젝트에서의 접근법(실험 기반)

- **1단계**: 데이터 샘플링으로 문서 특성(헤딩/표/반복 문구/용어)을 파악
- **2단계**: 여러 청킹 전략으로 A/B 테스트(예: Fixed vs Recursive, Overlap 유/무)
- **3단계**: 검색 품질과 비용(지연/저장/인덱싱 시간)을 **같이** 평가
- **4단계**: 지속적인 모니터링과 개선(로그/피드백 기반)

<a id="sec-1-4-7"></a>

### 1.4.7 실전 팁(바로 적용 가능한 가이드)

- **시작은 간단하게**: Fixed-size로 시작 → 문제를 “관찰”한 뒤 고도화
- **청크 크기 실험**: 256/512/1024 토큰 등 여러 크기 테스트
- **Overlap 비율**: 일반적으로 10–30%, 중요 문서는 50%까지도 고려
- **하이브리드 접근**: 여러 방법 조합(예: Semantic + Overlap)
- **검증 필수**: 청킹 후 **실제 검색 결과**(Top-K)로 품질 확인

#### 일반적인 실수들

- **과도한 최적화**: 초기부터 복잡한 전략 적용
- **데이터 무시**: 실제 문서/질문 패턴을 고려하지 않음
- **정적 접근**: 데이터 변화에 따른 전략 조정 부족
- **성능 무시**: 청킹 품질만 보고 처리 속도/비용을 무시

#### 핵심 원칙

> "완벽한 청킹 전략은 없다. 데이터를 이해하고, 실험하고, 개선하라."

##### 청킹 전략 최적화 팁

- **점진적 개선**
  - 기본 전략으로 시작 → 점진적으로 고도화
  - 각 단계별 성능 측정과 비교

- **하이브리드 접근**
  - 여러 전략을 조합하여 사용
  - 예: 의미 기반 + 중복 청킹

- **메타데이터 활용**
  - 청크에 출처, 타입, 중요도 등 정보 추가
  - 검색 시 필터링과 우선순위 설정 가능

- **지속적 모니터링**
  - 사용자 피드백 기반 개선
  - 검색 로그 분석을 통한 패턴 파악

> 중요한 관점: **청킹 전략에 ‘정답’은 없습니다.**  
> 비즈니스마다 문서 구조/용어/표현 방식이 다르고(일종의 **은어/암묵지**), “한 주제”의 경계도 조직마다 다르게 정의됩니다.  
> 따라서 Fixed/Recursive/Semantic 중 하나를 고르는 문제가 아니라, **우리 문서와 질문 패턴에 맞춰** 크기·오버랩·분할 기준을 **복합적으로, 전략적으로 설계/튜닝**하는 문제에 가깝습니다.

<a id="sec-1-3"></a>

## 1.3 텍스트를 숫자로 : 벡터 표현의 이해

LLM이 텍스트를 처리하려면 먼저 **숫자(벡터)**로 변환해야 합니다. 벡터 변환 방식은 크게 **희소 벡터**와 **밀집 벡터** 두 가지로 나뉘며, RAG 검색 성능을 좌우하는 핵심 개념입니다.

아래 그림은 **실제 텍스트들을 임베딩(밀집 벡터)으로 변환한 뒤**, **t-SNE로 2차원에 시각화**한 예시입니다.  
가까이 모여 있는 점일수록(군집) 보통 **의미적으로 비슷한 텍스트**라고 이해하면 됩니다.

![Embedding t-SNE 시각화 예시](asset/embedding_tsne_visualization.png)

> 참고 : t-SNE는 “고차원 벡터를 2차원으로 예쁘게 펼쳐서 보여주는” **시각화 기법**입니다.  
> (시각화를 위한 도구일 뿐, 원래 벡터 공간의 거리를 완벽히 보존하는 것은 아닙니다.)

**희소 벡터 (Sparse Vector) - 키워드 중심 검색**

- **표현 방식** : 단어의 등장 빈도와 중요도를 기반으로 벡터 생성
- **특징** : 대부분의 값이 0이고, 등장한 단어 위치만 0이 아닌 값

**동작 예시**
```
전체 단어 사전: ["강아지", "고양이", "귀엽다", "짖다", "야옹"]

문서 A: "강아지는 귀엽다"
→ 희소 벡터: [1, 0, 1, 0, 0]

문서 B: "고양이는 야옹하고 귀엽다"
→ 희소 벡터: [0, 1, 1, 0, 1]

벡터 차원: 전체 단어 사전 크기 (50,000개 단어 = 50,000차원)
```

**대표 알고리즘: BM25**

- TF-IDF의 개선 버전
- 문서 길이 정규화 및 단어 빈도 포화(saturation) 적용
- 키워드 기반 검색 시스템의 표준 (Elasticsearch, OpenSearch 등에서 사용)

**장점**
- 정확한 키워드 매칭 (예: "Python 3.11" 버전 검색)
- 구현이 단순하고 빠름
- 결과 해석이 직관적

**단점**
- 의미적 유사성을 이해하지 못함
  - "강아지"와 "멍멍이"를 완전히 다른 단어로 인식
- 동의어, 유의어 처리 불가

---

**밀집 벡터 (Dense Vector) - 의미 중심 검색**

- **표현 방식** : 딥러닝 모델이 학습한 의미를 저차원 벡터로 압축
- **특징** : 모든 값이 실수로 채워져 있으며, 의미적으로 유사한 텍스트는 벡터 공간에서 가까이 위치

**동작 예시**
```
문서 A: "강아지는 귀엽다"
→ 밀집 벡터 (384차원) : [0.72, -0.15, 0.43, ..., 0.91, -0.22]

문서 B: "멍멍이는 사랑스럽다"
→ 밀집 벡터 (384차원) : [0.69, -0.18, 0.40, ..., 0.88, -0.25]

→ 코사인 유사도: 0.94 (매우 유사)
→ 의미적으로 유사한 내용은 벡터 공간에서 가까이 위치
```

**대표 임베딩 모델**

- OpenAI : `text-embedding-3-small`, `text-embedding-3-large`
- 오픈소스 : `BGE-M3`, `Ko-SimCSE-roberta`, `Sentence-BERT`

**장점**
- 의미적 유사성을 정확히 포착
  - "강아지", "멍멍이", "개" 모두 유사하게 인식
- 문맥 이해 ("사과(과일)" vs "사과(apology)")
- 다국어, 신조어에 강함

**단점**
- 정확한 키워드 매칭에 약함
  - "Python 3.11"과 "Python 3.10"을 너무 유사하게 인식
- 계산 비용이 높음 (GPU 권장)

---

**비교표**

| 구분 | 희소 벡터(BM25) | 밀집 벡터(Embedding) |
|:---|:---|:---|
| **표현 방식** | 단어 빈도/통계 | 딥러닝 학습 |
| **벡터 차원** | 수만~수십만 | 384~1536 |
| **의미 이해** | ❌ 불가능 | ✅ 가능 |
| **키워드 매칭** | ✅ 강함 | ⚠️ 약함 |
| **계산 비용** | 낮음 | 높음 |
| **RAG 활용** | 정확한 용어 검색 | 의미 기반 검색(주류) |

**여기서 결론: “검색”을 가능하게 만드는 2개의 언어**

- 희소 벡터(BM25)는 **정확한 단어/버전/숫자/코드 같은 “그 표현 그대로”**를 잘 찾습니다.
- 밀집 벡터(Embedding)는 **표현이 달라도 의미가 비슷한 문장**을 잘 찾습니다.
- 그래서 RAG에서 Retrieval(검색)은 결국 “질문과 문서가 얼마나 가깝냐”를 **희소/밀집 중 하나(또는 둘 다)**의 기준으로 계산하는 일입니다.

> **🔍 더 깊이 학습하려면?**
>
> - **Transformer 아키텍처** : 밀집 벡터 생성의 핵심 기술 ([Attention Is All You Need](https://arxiv.org/abs/1706.03762))
> - **NLP 기초** : 자연어 처리의 역사와 토큰화, 정규화 등 ([Stanford CS224N](https://web.stanford.edu/class/cs224n/))
> - **임베딩 모델 비교** : MTEB Leaderboard에서 최신 모델 성능 확인
> - **보충 자료(PDF)** : 밀집 벡터 vs 희소 벡터 차이 정리 (`pdf/dense_sparse_vectors.pdf`)

---

<a id="sec-1-5"></a>

## 1.5 RAG 시스템의 구조와 작동 원리

RAG 파이프라인
```text
[문서 수집] → [청킹] → [임베딩] → [벡터 DB 저장]
                                  ↓
[사용자 요청] → [임베딩] → [유사도 검색] → [컨텍스트 구성] → [LLM 응답 생성]
```

앞 절에서 본 “벡터로 바꾸고 유사도를 계산한다”는 아이디어를 실제 서비스로 만들면, 보통 **(1) 문서를 미리 준비하는 단계**와 **(2) 질문이 들어왔을 때 찾아서 답하는 단계**로 나뉩니다.

> **핵심 비유: 오픈북 시험**
>
> - **LLM 단독** : 암기만으로 시험 보는 '클로즈북 시험' → 환각, 망각 발생
> - **RAG 활용** : 교과서를 찾아보며 시험 보는 '오픈북 시험' → 정확하고 최신 정보 제공

앞에서 본 RAG 파이프라인을 이제 **위에서 아래로** 하나씩 뜯어보겠습니다. 먼저 문서를 준비하는 **1단계(지식 준비/인덱싱)**부터 시작합니다.

RAG 시스템은 크게 **지식 준비**와 **검색 및 생성(Retrieval & Generation)** 두 단계로 작동합니다.

#### 1단계 : 지식 준비(지식 도서관 구축)

원본 문서를 미리 가공하여 LLM이 빠르고 정확하게 참조할 수 있는 '지식 창고(Vector Store)'를 구축하는 과정

**1) 데이터 로드 (Load)**

- 다양한 형태의 문서를 시스템에 불러옴
- 지원 형식 : PDF, TXT, HTML, DB 등

**2) 분할 (Split / Chunking)**

- 문서를 LLM이 한 번에 처리할 수 있는 작은 단위(Chunk)로 분할
- 청크의 크기와 분할 방식은 RAG 성능에 직접적인 영향을 미침

> 청킹의 목적/기본값/전략(3가지)은 앞에서 이미 정리했습니다. 여기서는 “지식 준비(인덱싱) 단계에서 청킹이 수행된다”는 흐름만 기억하면 됩니다.

**3) 임베딩 (Embedding)**

- 각 텍스트 청크를 숫자 벡터로 변환 (Chapter 1의 **1.4절(벡터 표현)**에서 학습)
  - 예: `[0.7, -0.2, 0.5, ...]` (384~1536차원)
- 의미적으로 유사한 텍스트는 벡터 공간에서 가까이 위치
  - "강아지"와 "멍멍이"는 유사한 벡터 값을 가짐
- 대표 모델: `OpenAI text-embedding-3-small`, `BGE-M3`, `Ko-SimCSE-roberta`

**4) 저장 (Store)**

- 임베딩된 벡터와 원본 텍스트 청크를 **벡터 데이터베이스(Vector Database)**에 저장
- 벡터 DB의 역할: 특정 '의미 좌표'와 가장 가까운 좌표들을 초고속으로 검색
    *   **대표적인 벡터 DB:** `FAISS`, `ChromaDB`, `Qdrant`

#### 2단계 : 검색 및 생성 (사용자 질문에 답변)

사용자의 질문이 들어왔을 때, 준비된 지식 창고를 참조하여 최종 답변을 생성하는 과정

**1) 사용자 질문 임베딩 (Embed Query)**

- 사용자 질문을 벡터로 변환
- 예 : "에펠탑은 누가 설계했어?" → `[0.3, -0.8, 0.5, ...]`

**2) 유사도 검색 (Similarity Search)**

- 질문 벡터와 가장 유사한 문서 청크를 검색
- 코사인 유사도 기반으로 Top-K개 선택 (예: 5개)

**3) 프롬프트 구성(Prompt Construction)**

- 검색된 청크(Context)를 사용자 질문과 함께 LLM에 전달

```
검색된 문서:
1. "에펠탑은 귀스타브 에펠이 설계했다..."
2. "1889년 파리 만국박람회를 위해 건설되었다..."

사용자 질문 : 에펠탑은 누가 설계했어?

위 문서를 참고하여 답변해주세요.
```

**4) 답변 생성(Generation)**

- LLM이 검색된 컨텍스트를 근거로 답변 생성
- 환각 방지 : 문서에 없는 내용은 생성하지 않음

---

**RAG의 기본 구조 끝**

이제 다음 Chapter 2에서는 “이론”을 “구현”으로 연결해서, 표준 RAG 파이프라인을 실제로 설계하고(청킹/임베딩/벡터DB/프롬프트) 동작시키는 과정을 다룹니다.  
에이전트/Agentic RAG는 Chapter 3에서 소개

---

<a id="sec-2-2"></a>

## 2.2 RAG가 해결하는 LLM의 핵심 문제점

RAG는 단순히 '외부 지식 추가' 이상의 의미를 가집니다. LLM의 근본적인 한계를 구조적으로 해결하는 아키텍처입니다.

| LLM의 문제 | RAG 해결 방식 | 실무 효과 |
| :--- | :--- | :--- |
| **할루시네이션 (Hallucination)** | 실제 문서를 기반으로 생성하여 근거 없는 답변 방지 | 신뢰도 향상, 법률/의료 등 정확성 중요 도메인에 필수 |
| **최신성 부족 (Knowledge Cut-off)** | 외부 DB, 크롤링 등으로 실시간 최신 정보 반영 | 뉴스, 주가, 날씨 등 시간 민감 정보 제공 가능 |
| **출처 확인 불가 (No Attribution)** | 벡터 DB 메타데이터 기반으로 출처 표기 | 학술 연구, 내부 규정 준수, 법적 책임 명확화 |
| **도메인 전문성 부족** | 도메인 문서만 확보하면 별도 파인튜닝 없이 전문성 확보 | 비용 절감 (파인튜닝 대비 10~100배), 빠른 배포 |
| **긴 입력의 Attention Decay** | 관련 부분만 선별하여 컨텍스트 최소화 | 답변 품질 향상, 토큰 비용 절감 |
| **개인화 어려움** | 사용자별 문서/대화 이력 저장으로 개인화 | 고객 맞춤형 서비스, 사용자 경험 향상 |

<a id="sec-2-2-example"></a>

### 실전 활용 예시: 기업 내부 문서 Q&A 시스템

**시나리오:** 5000페이지 분량의 회사 내규, 복리후생 안내, 프로젝트 문서를 학습시킨 RAG 시스템

*   **질문:** "재택근무 신청 기한은 언제까지인가요?"
*   **일반 LLM:** "일반적으로 재택근무는 1~2주 전에 신청하는 것이 좋습니다." (할루시네이션, 회사 규정과 무관)
*   **RAG 시스템:**
    1.  벡터 DB에서 "재택근무 신청 기한" 관련 문서 검색
    2.  검색 결과: `"재택근무 신청은 근무일 3일 전까지 팀장 승인 필요" [출처: 인사규정 2024.pdf, p.42]`
    3.  LLM 생성: "재택근무는 근무일 기준 3일 전까지 신청하셔야 하며, 팀장님의 승인이 필요합니다. (출처: 인사규정 2024.pdf, 42페이지)"

**효과:**
*   정확한 사내 규정 제공
*   출처 명시로 신뢰성 확보
*   HR 팀 문의 감소 → 업무 효율 향상

---

<a id="sec-2-3"></a>

## 2.3 LangChain 프레임워크: RAG 구현을 “빠르게” 돕는 도구(장단점 포함)

<a id="sec-2-3-1"></a>

### 2.3.1 LangChain이란?

**LangChain**은 LLM 애플리케이션을 만들 때 자주 반복되는 구성(프롬프트, 모델 호출, 리트리버, 출력 파서, 체인/에이전트 실행 등)을 **컴포넌트로 추상화**해 제공하는 오픈소스 프레임워크입니다.

> 이 교육에서는 LangChain을 “정답”이나 “표준”으로 다루기보다, **생산성을 높여주는 옵션**으로 보고, 필요할 때만 선택할 수 있도록 장단점을 함께 봅니다.

**핵심 개념**

*   **체인 (Chain):** 여러 컴포넌트를 연결하여 복잡한 작업을 수행하는 파이프라인
    *   예: `문서 로드 → 청킹 → 임베딩 → 검색 → LLM 생성` 을 하나의 체인으로 구성
*   **프롬프트 템플릿 (Prompt Template):** 재사용 가능한 프롬프트 구조 정의
    *   변수 삽입, 조건부 로직, Few-shot 예시 관리 등
*   **메모리 (Memory):** 대화 기록 및 컨텍스트를 관리하여 연속적인 대화 지원
    *   ConversationBufferMemory, ConversationSummaryMemory 등
*   **에이전트 (Agent):** 도구를 자율적으로 선택하고 실행하는 지능형 시스템
    *   Chapter 3~4에서 본격적으로 학습합니다.

<a id="sec-2-3-2"></a>

### 2.3.2 LangChain이 해결하는 문제

1.  **보일러플레이트 코드 제거**
    *   임베딩, 벡터 스토어 연결, 프롬프트 구성 등 반복적인 코드를 추상화
    *   순수 구현 대비 코드량을 줄이고, 시행착오를 빠르게 반복할 수 있음

2.  **다양한 통합 지원**
    *   LLM: OpenAI, Anthropic(Claude), Google(Gemini), Cohere 등 단일 인터페이스 지원
    *   벡터 DB: Chroma, Pinecone, Qdrant, Weaviate, FAISS 등 쉽게 전환 가능
    *   문서 로더: PDF, CSV, HTML, Notion, Google Drive 등 다양한 데이터 소스

3.  **LCEL (LangChain Expression Language)**
    *   파이프 연산자(`|`)를 사용한 직관적인 체인 구성
    *   자동 병렬 처리, 스트리밍, 배치 처리 지원
    *   **예시:**
        ```python
        chain = (
            {"context": retriever, "question": RunnablePassthrough()}
            | prompt
            | llm
            | StrOutputParser()
        )
        answer = chain.invoke("RAG란 무엇인가?")
        ```

<a id="sec-2-3-3"></a>

### 2.3.3 순수 구현 vs LangChain 비교

| 비교 항목 | 순수 구현 (Pure Python) | LangChain |
| :--- | :--- | :--- |
| **코드 복잡도** | 높음 (모든 것을 직접 구현) | 낮음 (추상화된 컴포넌트 사용) |
| **개발 속도** | 느림 (상세 구현 필요) | 빠름 (즉시 사용 가능) |
| **학습 곡선** | 가파름 (원리부터 이해) | 완만함 (사용법 위주) |
| **커스터마이징** | 높음 (모든 세부사항 제어 가능) | 중간 (프레임워크 범위 내에서 가능) |
| **디버깅** | 직접 추적 필요(도구는 자유) | 추상화로 빨라지지만, 내부가 블랙박스가 될 수 있음(LangSmith 등으로 보완) |
| **원리 이해** | 깊음 (직접 구현하며 학습) | 얕아질 수 있음 (내부 동작이 추상화됨) |
| **유지보수** | 직접 관리 필요 | 프레임워크/통합 모듈 업데이트에 영향을 받음(좋을 수도, 깨질 수도) |
| **성능 최적화** | 완전한 제어 가능 | 프레임워크 최적화에 의존 (일부 오버헤드 존재) |
| **코드 라인 수** | 많음 (~600줄) | 적음 (~100줄) |

<a id="sec-2-3-4"></a>

### 2.3.4 LangChain의 장점과 한계

**장점**

1.  **빠른 프로토타이핑:** 아이디어를 몇 시간 내에 동작하는 시스템으로 구현 가능
2.  **풍부한 통합:** 100+ LLM, 벡터 DB, 데이터 소스 지원
3.  **활발한 커뮤니티/예제:** 레퍼런스와 예제가 많아 시행착오를 줄이기 좋음
4.  **LangSmith 디버깅 도구:** 체인 실행 추적, 성능 모니터링, A/B 테스트 지원

**한계 및 주의사항**

1.  **추상화로 인한 블랙박스**
    *   내부 동작 원리 이해 어려움 → 예상치 못한 동작 발생 시 디버깅 곤란
    *   **권장:** 최소 한 번은 순수 구현으로 RAG 원리를 학습한 후 LangChain 사용

2.  **무거운 의존성**
    *   50+ 패키지 자동 설치 → 배포 용량 증가, 버전 충돌 가능성
    *   **해결:** `langchain-core`, `langchain-openai` 등 필요한 모듈만 선택 설치

3.  **성능 오버헤드(레이턴시)**
    *   “간단한 호출”도 내부적으로 여러 레이어를 거칠 수 있음

        ```python
        # - 체인 각 단계의 래퍼 호출
        # - 중간 결과 직렬화/역직렬화
        # - 로깅 및 추적
        # → 간단한 작업도 여러 레이어를 거침
        ```

    *   단순 작업에도 불필요한 처리가 붙어 **레이턴시가 증가**할 수 있음(대략 수십 ms ~ 수백 ms 수준의 추가 비용이 체감되는 케이스가 있음)
    *   **실무 판단:** “초저지연 실시간 서비스”라면 순수 구현/하이브리드를 적극 검토

4.  **프레임워크 버전 의존성**
    *   빠른 업데이트로 인한 Breaking Change가 비교적 잦음
    *   실습/예제 코드가 버전에 따라 작동하지 않을 수 있음
    *   예: `v0.0.x` → `v0.1.x` → `v0.2.x` 마이그레이션 필요
    *   **대응:** 버전 고정(`poetry` 또는 `requirements.txt`), 마이그레이션 가이드 확인, “동작하는 최소 버전”을 문서에 명시

5.  **커스터마이징 제약**
    *   프레임워크 설계 범위를 벗어난 요구사항 구현이 어려울 수 있음
    *   내장 컴포넌트를 깊게 수정하려 하면 상속/래핑 구조가 복잡해질 수 있음
    *   특수한 검색 로직이나 평가 지표(로그 기반 커스텀 스코어링 등) 구현 시 한계가 드러나기도 함

6.  **과도한 기능으로 인한 선택 피로**
    *   “할 수 있는 게 많다”는 장점이, 처음엔 오히려 선택 난이도가 될 수 있음

        ```python
        # Retriever 종류만 10가지 이상
        - VectorStoreRetriever
        - MultiQueryRetriever
        - EnsembleRetriever
        - ContextualCompressionRetriever
        - ParentDocumentRetriever
        - SelfQueryRetriever
        - TimeWeightedVectorStoreRetriever
        - ...
        
        # 어떤 것을 언제 써야 할지 혼란
        ```

<a id="sec-2-3-5"></a>

### 2.3.5 실무 의사결정 가이드

| 상황 | 권장 방식 |
| --- | --- |
| 개념 학습 및 원리 이해 | 순수 구현 |
| 빠른 프로토타입 제작 | LangChain |
| 성능 최적화가 중요한 프로덕션 | 순수 구현 또는 하이브리드 |
| 표준적인 RAG 파이프라인 | LangChain |
| 특수한 검색 알고리즘 필요 | 순수 구현 |
| 팀 전체가 LangChain 숙련도 높음 | LangChain |
| 레이턴시가 매우 중요(실시간 서비스) | 순수 구현 |

**권장 학습 로드맵**

1.  **1단계 (기초):** 순수 Python으로 RAG 구현 → 벡터 검색, 임베딩, 프롬프트 구성 원리 이해
2.  **2단계 (실무):** LangChain으로 프로젝트 구현 → 생산성과 유지보수성 체감
3.  **3단계 (고급):** 하이브리드 접근 → 중요한 부분은 커스터마이징, 나머지는 LangChain

---

**다음 Chapter 예고**

Chapter 3에서는 RAG를 더 똑똑하게 만드는 **고급 검색 기법**(하이브리드 검색, Re-ranking, Multi-hop Reasoning)과 **Agentic RAG로의 전환**을 다룹니다. 또한 실제 코드 구현을 통해 이론을 실전에 적용하는 방법을 학습합니다.

---

<a id="chapter-3"></a>

# Chapter 3: RAG 고급 기법과 Agentic RAG로의 전환

<a id="sec-3-1"></a>

## 3.1 RAG 검색 최적화 기법: 정확도를 높이는 고급 전략

기본 RAG(Chapter 2)는 단순히 벡터 유사도로 문서를 검색합니다. 하지만 실무에서는 더 정교한 검색 전략이 필요합니다. 이 섹션에서는 검색 품질을 획기적으로 향상시키는 3가지 핵심 기법을 다룹니다.

<a id="sec-3-1-1"></a>

### 3.1.1 하이브리드 검색 (Hybrid Search): 의미와 키워드의 조화

**핵심 아이디어:** 벡터 검색(의미 기반)과 키워드 검색(전통적 방식)을 결합하여 각각의 장점을 활용합니다.

#### 구성 요소

1.  **BM25 (Best Matching 25) - 키워드 기반 검색**
    *   TF-IDF의 진화 버전으로, 통계적 랭킹 알고리즘입니다.
    *   **강점:** 정확한 용어 매칭, 전문 용어나 고유명사 검색에 탁월
    *   **예시:** "Python 3.11.5" 같은 정확한 버전명, "서울시 강남구 테헤란로 152" 같은 주소 검색
    *   **작동 방식:**
        ```
        BM25 Score = Σ(IDF × (TF × (k+1)) / (TF + k × (1-b + b × 문서길이/평균문서길이)))

        - IDF: 희귀한 단어일수록 높은 가중치
        - TF: 문서 내 단어 빈도
        - k, b: 튜닝 파라미터 (보통 k=1.5, b=0.75)
        ```

2.  **벡터 검색 (Dense Vector Search) - 의미 기반 검색**
    *   임베딩을 통한 의미적 유사도 계산 (Chapter 1의 1.4절에서 학습)
    *   **강점:** 동의어, 유의어, 문맥 이해
    *   **예시:** "파이썬 최신 버전"이라는 질문으로 "Python 3.11" 문서 검색 가능

#### 스코어 결합 방법

| 방법 | 설명 | 수식 | 장점 | 단점 |
| :--- | :--- | :--- | :--- | :--- |
| **가중 평균** | 각 스코어에 가중치 부여 후 합산 | `score = α×BM25 + (1-α)×vector` | 간단, 직관적 | 스케일 차이 고려 필요 |
| **정규화 후 합산** | 0-1 범위로 정규화 후 합산 | `score = norm(BM25) + norm(vector)` | 스케일 통일 | 계산 비용 증가 |
| **RRF (Reciprocal Rank Fusion)** | 순위 기반 융합 | `score = Σ(1/(k+rank))` | 스코어 스케일 독립적 | 순위 정보만 사용 |

**RRF 상세 설명 (실무 표준)**

```
질문: "RAG 시스템 성능 개선"

BM25 결과 순위:
1위: [문서A] "RAG 성능 최적화 가이드" → RRF 점수: 1/(60+1) = 0.0164
2위: [문서B] "시스템 개선 전략" → RRF 점수: 1/(60+2) ≈ 0.0161
3위: [문서C] "RAG 아키텍처" → RRF 점수: 1/(60+3) ≈ 0.0159

벡터 검색 결과 순위:
1위: [문서C] "RAG 아키텍처" → RRF 점수: 1/(60+1) = 0.0164
2위: [문서A] "RAG 성능 최적화 가이드" → RRF 점수: 1/(60+2) ≈ 0.0161
3위: [문서D] "검색 증강 생성" → RRF 점수: 1/(60+3) ≈ 0.0159

최종 RRF 점수 (합산):
- 문서A: 0.0164 + 0.0161 = 0.0325 ← 1위 (두 검색에서 모두 상위권)
- 문서C: 0.0159 + 0.0164 = 0.0323 ← 2위
- 문서B: 0.0161 + 0 = 0.0161 ← 3위 (벡터 검색에서 누락)
- 문서D: 0 + 0.0159 = 0.0159 ← 4위 (BM25에서 누락)

→ 두 검색 방식에서 모두 관련성이 높은 문서A가 최종 1위
```

#### 실무 적용 가이드

| 도메인/상황 | 권장 비율 (BM25 : Vector) | 이유 |
| :--- | :--- | :--- |
| **기술 문서, API 레퍼런스** | 7:3 또는 6:4 | 정확한 함수명, 버전 등 키워드 매칭 중요 |
| **고객 FAQ, 일반 문서** | 3:7 또는 4:6 | 사용자 표현이 다양, 의미 파악 중요 |
| **법률, 규정 문서** | 8:2 | 정확한 조문 번호, 용어 매칭 필수 |
| **뉴스, 블로그** | 5:5 | 균형 잡힌 접근 |
| **다국어 문서** | 2:8 | 벡터가 언어 간 의미 유사성 파악에 유리 |

**구현 예시 (LangChain + Qdrant)**

```python
from langchain.retrievers import EnsembleRetriever
from langchain_community.retrievers import BM25Retriever
from langchain_qdrant import QdrantVectorStore

# BM25 검색기 (키워드)
bm25_retriever = BM25Retriever.from_documents(documents)
bm25_retriever.k = 5  # 상위 5개

# 벡터 검색기 (의미)
vector_store = QdrantVectorStore(...)
vector_retriever = vector_store.as_retriever(search_kwargs={"k": 5})

# 하이브리드 결합 (RRF 자동 적용)
ensemble_retriever = EnsembleRetriever(
    retrievers=[bm25_retriever, vector_retriever],
    weights=[0.4, 0.6]  # BM25 40%, Vector 60%
)

results = ensemble_retriever.invoke("RAG 시스템 성능 개선 방법")
```

---

<a id="sec-3-1-2"></a>

### 3.1.2 Re-ranking (재정렬): 2단계 정밀 검색

**핵심 아이디어:** 1차로 빠르게 후보를 추린 후, 2차로 정교한 모델로 재평가하여 최종 순위를 결정합니다.

#### 왜 2단계 검색이 필요한가?

*   **1단계 (Bi-encoder):** 속도 우선, 대량 문서에서 후보 추출 (Recall 중시)
*   **2단계 (Cross-encoder):** 정확도 우선, 소수 후보 정밀 평가 (Precision 중시)

#### Bi-encoder vs Cross-encoder 비교

**1) Bi-encoder (듀얼 인코더) - 1단계 검색**

```
Query: "딥러닝 학습 방법"
Document: "딥러닝은 역전파를 통해 학습합니다."

처리 과정:
Query → Encoder → [0.2, 0.5, 0.8, ...] (512차원) ─┐
                                                   ├─> Cosine Similarity → 0.87
Document → Encoder → [0.3, 0.6, 0.75, ...] (512차원)─┘

특징:
✓ Query와 Document를 독립적으로 임베딩
✓ 문서 임베딩을 사전에 계산하여 DB에 저장 가능 (캐싱)
✓ 검색 시 Query 임베딩만 생성 → 코사인 유사도 계산 (초고속)
✗ Query와 Document 간 상호작용(Attention) 없음
```

**2) Cross-encoder (크로스 인코더) - 2단계 Re-ranking**

```
[Query + Document]를 하나의 입력으로 처리

입력: "[CLS] 딥러닝 학습 방법 [SEP] 딥러닝은 역전파를 통해 학습합니다. [SEP]"
      ↓
   Transformer (BERT 기반)
      ↓
   [CLS] 토큰의 임베딩
      ↓
   Classifier (관련성 점수)
      ↓
   0.94 (0~1 범위, 높을수록 관련성 높음)

특징:
✓ Query와 Document를 함께 처리하여 상호작용 파악 (Cross-attention)
✓ 문맥 이해도 매우 높음 (단어 간 관계, 의미의 뉘앙스 포착)
✓ 높은 정확도
✗ 느린 속도 (모든 Query-Document 쌍을 실시간 계산해야 함)
✗ 사전 캐싱 불가능
```

#### 성능 비교 및 실전 파이프라인

| 특성 | Bi-encoder | Cross-encoder |
| :--- | :--- | :--- |
| **속도** | 매우 빠름 (ms 단위) | 느림 (초 단위) |
| **정확도** | 중간 | 매우 높음 |
| **계산 비용** | 낮음 | 높음 (GPU 권장) |
| **문맥 이해** | 독립적 (상호작용 X) | 상호작용 (Attention) |
| **사용 단계** | 1단계 (대량 필터링) | 2단계 (정밀 평가) |
| **캐싱** | 가능 (문서 임베딩 저장) | 불가능 (실시간 계산 필수) |
| **적용 규모** | 100만+ 문서 | 수십~수백 개 후보 |

**실무 파이프라인 예시**

```
[전체 데이터: 100만 개 문서]
         ↓
   1단계: Bi-encoder 벡터 검색
         ↓
  [상위 100개 후보 추출] (1~5ms, Recall 확보)
         ↓
   2단계: Cross-encoder Re-ranking
         ↓
  [최종 5개 선정] (100~500ms, Precision 극대화)
         ↓
     LLM에 전달
```

**구현 예시 (LangChain + Cohere Rerank API)**

```python
from langchain.retrievers import ContextualCompressionRetriever
from langchain.retrievers.document_compressors import CohereRerank
from langchain_qdrant import QdrantVectorStore

# 1단계: Bi-encoder 검색 (100개 추출)
vector_store = QdrantVectorStore(...)
base_retriever = vector_store.as_retriever(search_kwargs={"k": 100})

# 2단계: Cross-encoder Re-ranking (상위 5개 선정)
reranker = CohereRerank(
    model="rerank-multilingual-v2.0",  # 다국어 지원
    top_n=5  # 최종 5개만 선택
)

compression_retriever = ContextualCompressionRetriever(
    base_compressor=reranker,
    base_retriever=base_retriever
)

# 실행
results = compression_retriever.invoke("딥러닝 학습 방법")
# → 1단계에서 100개 추출 후, 2단계에서 가장 관련성 높은 5개 반환
```

**주요 Re-ranking 모델**

| 모델 | 제공 | 특징 | 비용 |
| :--- | :--- | :--- | :--- |
| **Cohere Rerank** | API | 다국어 지원, 높은 정확도 | 유료 (쿼리당 과금) |
| **bge-reranker-large** | 오픈소스 (BAAI) | 무료, 로컬 실행 가능 | 무료 (GPU 필요) |

---

<a id="sec-3-1-3"></a>

### 3.1.3 Multi-hop Reasoning (다단계 추론): 복잡한 질문 해결

**핵심 아이디어:** 한 번의 검색으로 답할 수 없는 복잡한 질문을 여러 단계로 나누어 순차적으로 검색하고 추론합니다.

#### 필요한 경우

*   단일 문서로는 답변 불가능한 복잡한 질문
*   여러 정보를 종합해야 하는 추론 작업
*   A를 알아야 B를 검색할 수 있는 연쇄적 질문

#### 예시: 연쇄 추론이 필요한 질문

**질문:** "GPT-4를 개발한 회사의 CEO가 창업한 또 다른 회사는?"

**일반 RAG의 한계:**
*   "GPT-4 CEO 창업 회사"로 검색 → 직접적인 문서 없음
*   단일 검색으로는 답변 불가능

**Multi-hop Reasoning 해결 과정:**

```
1단계 검색: "GPT-4를 개발한 회사는?"
→ 검색 결과: "OpenAI가 GPT-4를 개발함"
→ 중간 결론: 회사 = OpenAI

2단계 검색: "OpenAI의 CEO는?"
→ 검색 결과: "Sam Altman이 OpenAI CEO"
→ 중간 결론: CEO = Sam Altman

3단계 검색: "Sam Altman이 창업한 또 다른 회사는?"
→ 검색 결과: "Sam Altman은 Loopt, Y Combinator를 공동 창업"
→ 최종 답변: "Sam Altman이 창업한 회사는 Loopt와 Y Combinator가 있습니다."
```

#### 동작 방식 비교

**1) 체이닝 방식 (Sequential Chaining)**

```
질문 → 1차 검색 → 키워드 추출 → 2차 검색 → 키워드 추출 → 3차 검색 → 답변
       ↓               ↓               ↓
    컨텍스트 1      컨텍스트 2      컨텍스트 3
                        ↓
                  누적 컨텍스트 → LLM에 전달
```

**2) 병렬 검색 방식 (Parallel Decomposition)**

```
"GPT-4를 개발한 회사의 CEO가 창업한 또 다른 회사는?"
        ↓
   질문 분해 (LLM)
        ↓
   ┌───────┬───────┬───────┐
   ↓       ↓       ↓       ↓
Q1:GPT-4  Q2:OpenAI Q3:Sam   (병렬 검색)
  개발사    CEO    Altman창업
   ↓       ↓       ↓
  결과1   결과2   결과3
        ↓
   결과 통합 (LLM)
        ↓
     최종 답변
```

#### 구현 전략 및 주의사항

**반복 횟수 제한**
*   무한 루프 방지 (보통 2~3회로 제한)
*   너무 많은 홉은 오히려 노이즈 증가, 비용 증가

**중간 결과 검증**
*   각 단계에서 관련성 확인
*   예: "검색 결과가 이전 질문과 관련이 있는가?" 체크

**컨텍스트 축적**
*   이전 검색 결과를 다음 검색에 활용
*   LLM에게 "지금까지 알아낸 정보"를 계속 제공

**주의사항**

| 문제 | 설명 | 해결책 |
| :--- | :--- | :--- |
| **계산 비용 증가** | 여러 번의 검색 + LLM 호출 | 캐싱, 병렬 처리, 홉 수 제한 |
| **에러 전파** | 초기 검색 실패 시 전체 실패 | 각 단계 검증, Fallback 로직 |
| **응답 지연** | 순차 처리로 인한 지연 | 병렬 검색, 비동기 처리 |
| **불필요한 복잡성** | 단순 질문에도 Multi-hop 적용 | 질문 복잡도 분류 후 선택적 사용 |

**실무 적용 예시 (LangChain)**

```python
from langchain.chains import RetrievalQA
from langchain.chains.query_constructor.base import AttributeInfo
from langchain.retrievers.multi_query import MultiQueryRetriever

# Multi-hop을 위한 체인 구성
class MultiHopRAG:
    def __init__(self, retriever, llm):
        self.retriever = retriever
        self.llm = llm
        self.max_hops = 3

    def run(self, query):
        context = []
        current_query = query

        for hop in range(self.max_hops):
            # 현재 질문으로 검색
            docs = self.retriever.invoke(current_query)
            context.extend(docs)

            # LLM에게 "다음 단계 질문이 필요한가?" 물어보기
            prompt = f"""
            원래 질문: {query}
            지금까지 수집한 정보: {context}

            이 정보로 충분히 답변할 수 있나요?
            - 충분하면 "DONE"
            - 더 검색이 필요하면 다음 검색 쿼리를 제시
            """

            response = self.llm.invoke(prompt)

            if "DONE" in response:
                break  # 충분한 정보 수집

            # 다음 홉 질문 생성
            current_query = response  # LLM이 제시한 다음 쿼리

        # 최종 답변 생성
        return self.generate_answer(query, context)
```

---

<a id="sec-3-2"></a>

## 3.2 Agentic RAG로의 전환: 정적 파이프라인을 넘어서

RAG가 답변을 **정확하게(grounded)** 만든다면, **Agentic RAG**는 답변 과정을 **능동적으로(스스로 다음 행동을 선택)** 만듭니다.  
즉, “검색→생성” 한 번으로 끝나는 정적 파이프라인을 넘어, 필요하면 **되묻고 / 재검색하고 / 비교·검증하고 / 도구를 호출**하며 목표를 달성하는 방식입니다.

<a id="sec-3-2-1"></a>

### 3.2.1 AI 에이전트 : 스스로 일하는 '디지털 비서'

RAG가 AI를 더 정확하게 만든다면, **AI 에이전트**는 AI를 더 **자율적이고 능동적**으로 만듭니다. 에이전트는 단순히 질문에 답하는 것을 넘어, **목표를 주면 스스로 계획을 세우고, 필요한 도구를 사용하며, 문제를 해결**하는 '디지털 비서'와 같습니다.

#### AI 에이전트 vs 룰 베이스 시스템: 무엇이 다른가?

많은 분들이 AI 에이전트를 처음 접할 때, "기존의 챗봇이나 자동화 시스템과 뭐가 달라?"라고 궁금해하시곤 합니다. 가장 핵심적인 차이점을 일상 속 비유와 실제 시스템 예시로 알아보겠습니다.

##### 일상 비유 : 식당 직원 vs 키오스크

**식당에서 주문 받는 직원(AI 에이전트)**

```
목표: 고객이 만족하는 식사 경험 제공

1. 환경 인지 : 고객이 "매운 거 못 먹어요"라고 말함
2. 의사결정 : "매운 메뉴는 추천하면 안 되겠네. 순한 메뉴를 권해야지"
3. 행동 : "떡볶이는 매우니까 크림 파스타는 어떠세요?"
4. 피드백 : 고객이 "좋아요" → 주문 받기 / "파스타도 싫어요" → 다른 메뉴 제안
```

**키오스크(룰 베이스 시스템)**

```
1. 화면 표시 : "메뉴를 선택하세요"
2. 고객이 매운 메뉴 선택
3. 주문 완료
→ 고객이 매운 거 못 먹는지 알 수도 없고, 알아도 대응 못 함
```

  **AI 에이전트와 일반 프로그램의 차이:**

  | 구분           | 일반 프로그램(예: 계산기)          | AI 에이전트(예: 챗봇)                      |
  | -------------- | ----------------------------------- | ------------------------------------------- |
  | 입력           | 명확한 명령어(2 + 3)               | 모호한 요청("배가 고픈데 뭐 먹을까?")      |
  | 처리 방식      | 정해진 알고리즘 실행                | 상황 분석 후 판단                           |
  | 출력           | 정확한 결과(5)                     | 추론 기반 제안("근처 식당 추천드릴게요")   |
  | 실패 시        | 에러 메시지("잘못된 입력")         | 다른 방법 시도("무슨 음식 좋아하세요?")    |
  | 환경 변화 대응 | 재실행 필요(개발자가 다시 입력)    | 스스로 적응("날씨가 추우니 따뜻한 음식은?") |

##### 실제 시스템 비교 : 고객 문의 처리 사례

**시나리오** : "3일 전에 주문했는데 아직 안 왔어요. 취소하고 싶어요."

**기존 룰 베이스 챗봇의 처리**

```python
if "주문" in 문의 and "안 왔" in 문의:
    return "배송 조회는 주문번호를 입력해주세요."
elif "취소" in 문의:
    return "취소는 주문 후 24시간 이내만 가능합니다."

# 문제점:
# - 두 의도(배송 조회 + 취소)가 섞여있는 복합 문의 처리 불가
# - 대화 맥락 없이 매번 처음부터 시작
# - 고객의 감정(불만, 걱정) 이해 불가
```

**AI 에이전트의 지능적 처리**

```python
# 사이클 1 : 상황 이해 및 정보 수집
관찰: "3일 전에 주문했는데 아직 안 왔어요. 취소하고 싶어요."
사고: 고객이 배송 지연으로 인해 취소를 원하는 상황
     → 먼저 배송 상태를 확인해야 정확한 대응 가능
     → 주문번호가 필요함, 고객 이력에서 찾아보자
행동: get_customer_history(customer_id) 호출
결과: 최근 주문번호 "ORD-12345" 발견

# 사이클 2 : 구체적 정보 확인
사고: 주문번호를 찾았으니 배송 상태를 확인
행동: get_order_status("ORD-12345") 호출
결과: {"status": "배송중", "예상도착": "내일", "지연사유": "물류센터 혼잡"}

# 사이클 3 : 종합적 해결책 제시
사고: 배송이 이미 진행 중이고 내일 도착 예정
     → 취소는 불가능하지만, 도착 후 반품/환불 안내 가능
     → 지연에 대한 사과와 함께 대안 제시 필요
행동: 종합적 응답 생성
출력: "죄송합니다. 물류센터 혼잡으로 배송이 지연되었습니다.
      현재 배송 중이며 내일 오후 도착 예정입니다.
      배송 시작 후라 취소는 어렵지만,
      수령 후 7일 이내 무료 반품/환불이 가능합니다.
      불편을 드려 5,000원 쿠폰을 발급해드렸습니다."
```

##### AI 에이전트의 핵심 장점

| 능력         | 구체적 예시                                                           |
| ------------ | --------------------------------------------------------------------- |
| **맥락 이해**    | "아직 안 왔다" = 배송 지연 → "취소" = 불만 표현 → 통합적 상황 파악   |
| **동적 도구 선택** | 고객 이력 조회 → 주문 조회 → 쿠폰 발급까지 필요에 따라 순차적 실행 |
| **적응적 응답**  | 단순 정책 안내가 아닌 상황별 공감 + 대안 제시 + 보상                 |
| **불확실성 대응** | 주문번호를 직접 말하지 않아도 추론하여 처리                          |
| **자율성**       | 개발자가 "지연 시 쿠폰 발급" 규칙을 명시하지 않아도 상황 판단하여 제안 |

##### 인간 개입 최소화의 진정한 의미

- **룰 베이스** : **실행 자동화** (정해진 순서대로 실행, 판단은 개발자가 사전에 코딩)
- **AI 에이전트** : **판단 자율화** (상황을 분석하고 스스로 행동을 결정)

**예시:**
- 룰 베이스 : `if 배송지연 > 3일: send_coupon()` ← 개발자가 모든 케이스를 코딩
- AI 에이전트 : "고객이 화난 것 같고 배송이 지연됐네? 보상이 필요할 것 같다" ← 스스로 판단

##### 한계와 현실적 고려사항

**AI 에이전트의 한계**
- **도구와 지식 범위의 제약** : 개발자가 제공한 도구와 데이터 범위 내에서만 동작
- **LLM 자체의 한계** : 할루시네이션, 추론 오류, 맥락 길이 제한
- **운영상 제약** : 비용, 응답시간, 안전장치로 인한 제약

```
AI 에이전트가 할 수 있는 것
= LLM이 추론할 수 있는 것 (모델 능력)
× 개발자가 제공한 것 (도구 + 지식 + 제약조건)
```
**AI 에이전트 한계 = LLM의 한계 + 개발자 설계 범위의 한계**

**실무 권장사항**
- 단순하고 명확한 작업 → 룰 베이스 시스템이 더 빠르고 정확
- 복잡하고 맥락적인 작업 → AI 에이전트가 효과적
- **하이브리드 접근**: 룰 베이스 + AI 에이전트 조합이 현실적 해법

**핵심 결론** : AI 에이전트는 '만능'이 아니라, **똑똑하지만 개발자가 설정한 울타리 안에서만 자유로운 시스템**입니다. 실무에서는 각각의 장점을 살린 적절한 조합이 중요합니다.

| 질문                           | 답변                                                                 |
| ------------------------------ | -------------------------------------------------------------------- |
| AI 에이전트가 똑똑하다고?      | ✓ 맞음. **하지만 개발자가 준 장난감(도구)으로만 놀 수 있는 똑똑한 아이** |
| 새로운 기능을 스스로 만들어?   | ✗ 절대 불가. 개발자가 도구를 추가해줘야 함                           |
| 모든 질문에 답할 수 있어?      | ✗ 학습된 지식 + RAG 데이터 범위 내에서만 가능                        |
| 룰 베이스를 완전 대체할 수 있어? | ✗ 보완재임. 명확한 규칙은 룰 베이스가 더 빠르고 정확함               |

**따라서:**
- **AI 에이전트 ≠ 만능**, **AI 에이전트 = 똑똑하지만 울타리 안에서만 자유로운 시스템**
- 실무 설계 시 핵심 질문: "이 에이전트가 성공하려면 어떤 도구와 지식을 줘야 하나?"
- 룰 베이스 + AI 에이전트 혼합이 현실적 해법


#### AI 에이전트의 핵심 구성 요소

AI 에이전트는 특정 목표를 달성하기 위해 자율적으로 행동하는 시스템으로, 크게 4가지 핵심 요소로 구성됩니다.

1.  **LLM (The Brain) :** 에이전트의 핵심 두뇌 역할을 하는 대규모 언어 모델입니다. 모든 추론, 계획, 의사결정의 중심입니다.
2.  **계획 (Planning) :** 사용자의 복잡한 목표를 달성 가능한 작은 하위 작업들로 분해하고, 전체적인 실행 계획을 수립합니다.
    *   **예시:** "최근 일주일간의 AI 뉴스 요약 보고서 작성"이라는 목표를 받으면, 에이전트는 `1. 'AI 뉴스' 키워드로 웹 검색 -> 2. 검색 결과에서 신뢰할 수 있는 기사 선택 -> 3. 각 기사 내용 요약 -> 4. 전체 내용을 취합하여 보고서 형태로 작성` 과 같이 계획을 수립합니다.
3.  **기억 (Memory):** 과거의 행동과 그 결과를 기억하여 현재의 의사결정에 활용합니다.
    *   **단기 기억 (Short-term Memory):** 현재 대화나 작업의 컨텍스트를 유지합니다. (예: 방금 사용한 도구의 결과)
    *   **장기 기억 (Long-term Memory):** 과거의 경험, 성공/실패 사례 등을 장기적으로 저장하여 미래의 행동을 최적화합니다. (RAG의 벡터 DB가 장기 기억의 한 형태로 활용될 수 있습니다.)
4.  **도구 사용 (Tool Use):** LLM 자체의 한계를 극복하기 위해 외부 도구(API)를 호출하여 정보를 얻거나 특정 작업을 수행합니다.
    *   **예시 도구:** 웹 검색 API, 계산기 API, 코드 실행기, 데이터베이스 조회 API, RAG 시스템 등

#### 에이전트의 작동 매커니즘 : ReAct 프레임워크

에이전트는 **ReAct (Reason + Act)** 라는 원칙에 따라 **"생각 -> 행동 -> 관찰"** 사이클을 반복하며 목표를 향해 나아갑니다.

*   **상황:** "파리 날씨를 보고, 날씨에 맞는 옷차림을 추천해줘." 라는 목표 부여.

1.  **생각 (Thought):** "사용자가 두 가지를 원하네. 첫째, 파리의 현재 날씨. 둘째, 옷차림 추천. 먼저 날씨부터 알아봐야겠다. '웹 검색' 도구가 가장 좋겠어."
2.  **행동 (Action):** `웹 검색('파리 현재 날씨')` 라는 도구를 사용한다.
3.  **관찰 (Observation):** "검색 결과: '파리 현재 기온 15도, 강수 확률 80%'. 아, 춥고 비가 오는구나."
4.  **생각 (Thought):** "날씨를 확인했으니 이제 옷차림을 추천해야지. 15도에 비가 오면 쌀쌀하니까 재킷이 좋겠고, 우산도 필수겠네."
5.  **행동 (Action):** 사용자에게 최종 답변을 생성한다 : "현재 파리 날씨는 15도에 비가 오고 있습니다. 쌀쌀할 수 있으니 가벼운 재킷과 우산을 챙기시는 걸 추천합니다."

---

<a id="sec-3-2-2"></a>

### 3.2.2 기존 RAG의 한계와 Agentic RAG의 필요성

**기존 RAG (Static Pipeline)**의 한계:

1.  **고정된 실행 경로:** `검색 → 생성`의 단방향 흐름만 가능
    *   검색 결과가 부족해도 재검색 불가
    *   질문이 복잡해도 동일한 프로세스만 반복

2.  **단일 정보 소스 의존:** 미리 정의된 벡터 DB만 사용
    *   실시간 정보(날씨, 주가 등) 조회 불가
    *   외부 API, 웹 검색 등 활용 불가

3.  **수동적 검색:** 사용자의 질문을 그대로 사용
    *   질문이 모호하거나 부정확해도 수정 불가
    *   복합 질문을 단계별로 분해하지 못함

**Agentic RAG가 해결하는 문제:**

```
사용자 질문: "지난 분기 매출 증가율과 경쟁사 대비 성장률을 비교하고,
             주요 성공 요인을 분석해줘."

[기존 RAG의 처리]
→ "매출 증가율 경쟁사 성장률 성공 요인"으로 벡터 검색
→ 관련 문서 몇 개 찾아서 LLM에 전달
→ "검색된 정보가 부족합니다" 또는 부정확한 답변

[Agentic RAG의 처리]
1. 에이전트 분석: "이 질문은 3가지 하위 작업으로 나눌 수 있네."
   - 작업1: 우리 회사 지난 분기 매출 데이터 검색
   - 작업2: 경쟁사 매출 데이터 검색 (또는 웹 검색)
   - 작업3: 성공 요인 분석 보고서 검색

2. 도구 선택 및 실행:
   - [도구1: 내부 DB RAG] "2024년 4분기 우리 회사 매출"
   - [도구2: 웹 검색 API] "경쟁사 A, B 2024년 4분기 실적"
   - [도구3: 내부 DB RAG] "4분기 성공 요인 분석 보고서"

3. 결과 종합:
   - 수집된 3개 정보를 통합하여 비교 분석
   - 최종 답변 생성: "우리 회사 매출 15% 증가, 경쟁사 평균 8% 증가..."
```

<a id="sec-3-2-3"></a>

### 3.2.3 Tool-using Agent 설계 패턴

**핵심 원리:** RAG를 "시스템의 핵심"에서 "에이전트가 사용하는 여러 도구 중 하나"로 전환

#### 에이전트의 도구 목록 예시

```python
tools = [
    # 1. RAG 도구
    {
        "name": "company_knowledge_search",
        "description": "회사 내부 문서(규정, 보고서 등)에서 정보를 검색합니다.",
        "function": rag_retriever.invoke
    },
    # 2. 웹 검색 도구
    {
        "name": "web_search",
        "description": "최신 뉴스, 경쟁사 정보 등 실시간 정보를 검색합니다.",
        "function": tavily_search_api.run
    },
    # 3. 계산기 도구
    {
        "name": "calculator",
        "description": "수치 계산을 수행합니다.",
        "function": calculator.run
    },
    # 4. SQL 조회 도구
    {
        "name": "database_query",
        "description": "내부 데이터베이스에서 실적 데이터를 조회합니다.",
        "function": sql_database.query
    }
]
```

#### (실습 코드) Edu Agentic RAG 백엔드를 Tool로 매핑하기

이 레포의 실습 코드에서는 “도구(tool)”가 **마이크로서비스 HTTP API**로 제공됩니다. 즉, 에이전트 입장에서는 아래 서비스들을 호출하는 것이 곧 tool-use 입니다.

- `chatbot-service` (8000): 오케스트레이터(에이전트) 역할
- `weather-service` (8001): 날씨 조회
- `calendar-service` (8002): 일정 조회/생성
- `file-service` (8003): 파일 검색/조회/생성
- `notification-service` (8004): 알림 발송/히스토리 조회
- `rag-service` (8005): RAG 검색/인덱싱 (Qdrant 필요)

로컬 실행(백엔드 전체):

```bash
cd code/backend
python start_services.py
```

“tool 목록”을 이 프로젝트 관점으로 쓰면 예를 들어 이런 형태입니다:

```python
tools = [
    {"name": "get_weather", "endpoint": "GET http://localhost:8001/weather/{city}"},
    {"name": "get_calendar_today", "endpoint": "GET http://localhost:8002/calendar/today"},
    {"name": "search_files", "endpoint": "GET http://localhost:8003/files/search?q=..."},
    {"name": "send_notification", "endpoint": "POST http://localhost:8004/notifications/send"},
    {"name": "rag_query", "endpoint": "POST http://localhost:8005/rag/query"},
]
```

#### 에이전트의 의사결정 흐름 (ReAct 패턴)

**ReAct = Reasoning (추론) + Acting (행동)**

```
사용자: "우리 회사 직원 수와 애플의 직원 수를 비교해줘."

[Cycle 1]
Thought: "두 가지 정보가 필요해. 하나는 내부 정보, 하나는 외부 정보."
Action: company_knowledge_search("우리 회사 직원 수")
Observation: "2024년 기준 3,500명"

[Cycle 2]
Thought: "애플 직원 수는 내부 DB에 없을 거야. 웹 검색을 써야겠어."
Action: web_search("Apple Inc 직원 수 2024")
Observation: "애플은 약 164,000명의 직원 보유 (2024)"

[Cycle 3]
Thought: "두 정보를 모두 수집했으니 이제 답변을 만들자."
Action: Final Answer
Output: "우리 회사는 3,500명, 애플은 164,000명의 직원을 보유하고 있습니다.
         애플이 약 47배 더 많은 직원을 보유하고 있습니다."
```

**ReAct 프롬프트 예시 (LangChain)**

```python
from langchain.agents import create_react_agent
from langchain_core.prompts import PromptTemplate

react_prompt = PromptTemplate.from_template("""
당신은 사용자 질문에 답변하기 위해 도구를 사용할 수 있는 AI 에이전트입니다.

사용 가능한 도구:
{tools}

도구 이름: {tool_names}

다음 형식을 엄격히 따르세요:

질문: 답변해야 할 사용자 질문
Thought: 무엇을 해야 할지 추론합니다
Action: 사용할 도구 [{tool_names} 중 하나]
Action Input: 도구에 전달할 입력
Observation: 도구 실행 결과
... (Thought/Action/Observation을 필요한 만큼 반복)
Thought: 이제 최종 답변을 알았습니다
Final Answer: 사용자에게 전달할 최종 답변

시작!

질문: {input}
Thought: {agent_scratchpad}
""")

agent = create_react_agent(llm, tools, react_prompt)
```

<a id="sec-3-2-4"></a>

### 3.2.4 기존 RAG vs Agentic RAG 비교 (최종 정리)

| 비교 항목 | 기존 RAG | Agentic RAG |
| :--- | :--- | :--- |
| **실행 경로** | 고정적 (항상 검색 → 생성) | 동적 (상황에 따라 다른 경로) |
| **자율성** | 없음 (사람이 설계한 파이프라인) | 높음 (에이전트가 스스로 판단) |
| **도구 사용** | RAG만 사용 | RAG + 웹 검색 + SQL + 계산기 등 |
| **실패 대응** | 재시도 로직 수동 구현 필요 | 자동으로 다른 전략 시도 |
| **복잡한 질문** | 단일 검색으로 제한적 대응 | 다단계 분해하여 순차 해결 |
| **최신 정보** | 벡터 DB 내 정보만 (업데이트 전까지 불가) | 웹 검색으로 실시간 정보 조회 가능 |
| **개발 난이도** | 낮음 | 높음 (에이전트 설계, 프롬프트 엔지니어링) |
| **비용/지연** | 낮음 (검색 1회 + LLM 1회) | 높음 (여러 도구 호출 + LLM 다수 호출) |
| **적합한 사용처** | 단순 문서 검색, FAQ | 복잡한 분석, 실시간 정보 통합 |

---

<a id="sec-3-3"></a>

## 3.3 Multi-Agent: '어벤져스 팀'처럼 협력하는 AI들

복잡한 프로젝트를 혼자 다 할 수 없듯, AI도 여러 전문가가 팀을 이루면 더 강력해집니다. **멀티 에이전트** 시스템은 각자 다른 전문성을 가진 AI 에이전트들이 **하나의 팀처럼 협력**하여 공동의 목표를 달성하는 구조입니다.

> **핵심 비유:**
> 환자가 병원에 오면, 접수 데스크(오케스트레이터)가 환자의 상태를 보고 내과, 외과, 영상의학과 등 적절한 전문의(전문 에이전트)에게 진료를 연결해줍니다. 각 전문의는 자신의 분야에서 진단하고, 그 결과를 종합하여 최종 처방을 내리는 것과 같습니다.


1인 식당 (단일 에이전트)
┌─────────────────────────┐
│  사장님 혼자 모든 일    │
│  - 주문 받기            │
│  - 요리하기             │
│  - 서빙하기             │
│  - 계산하기             │
└─────────────────────────┘
✓ 간단한 메뉴 (라면, 김밥)
✗ 복잡한 요리 어려움
✗ 손님 많으면 한계

팀 레스토랑 (멀티 에이전트)
┌────────────────────────────────────┐
│ 홀 매니저: 주문 받고 전체 조율     │
│   ↓ 작업 분배                      │
│ ├→ 셰프: 메인 요리                 │
│ ├→ 소믈리에: 와인 추천             │
│ ├→ 파티시에: 디저트                │
│ └→ 계산대: 결제 처리               │
│   ↓ 결과 통합                      │
│ 홀 매니저: 손님에게 코스 제공      │
└────────────────────────────────────┘
✓ 복잡한 코스 요리 가능
✓ 각자 전문 분야 집중
✓ 동시 처리로 빠름
```

**단일 vs 멀티 에이전트: 언제 멀티가 필요한가?**

| 상황                       | 단일 에이전트              | 멀티 에이전트                  | 권장           |
| -------------------------- | -------------------------- | ------------------------------ | -------------- |
| 간단한 고객 문의           | ✓ 빠르고 간단              | ✗ 복잡도만 증가 (오버엔지니어링) | 단일           |
| 여러 전문 분야 필요        | ✗ LLM 하나로는 깊이 부족   | ✓ 각 분야 전문 에이전트        | 멀티           |
| 높은 정확도/검증 필요      | ✗ 자체 검증 한계           | ✓ 작성+검증 에이전트 분리      | 멀티           |
| 대량 데이터 병렬 처리      | ✗ 순차 처리 느림           | ✓ 동시 실행으로 속도 향상      | 멀티           |
| 다양한 관점/창의성 필요    | ✗ 단일 관점               | ✓ 여러 에이전트 토론           | 멀티           |
| 비용/시간 제약 있음        | ✓ LLM 호출 1회             | ✗ 여러 에이전트 호출로 비싸고 느림 | 단일           |


<a id="sec-3-3-arch"></a>

### 멀티 에이전트 시스템의 아키텍처

1.  **에이전트 오케스트레이터 (Agent Orchestrator / Router):**
    *   '프로젝트 매니저' 또는 '캡틴 아메리카'와 같은 역할. 사용자의 요청을 가장 먼저 받아, 그 의도를 분석(Intent Classification)합니다.
    *   분석된 의도에 따라 어떤 전문 에이전트에게 작업을 할당할지 결정하고, 전체 작업 흐름을 조율합니다.
2.  **전문 에이전트 (Specialist Agents):**
    *   각자 특정 분야에 특화된 기술과 도구를 가진 '어벤져스 멤버'들입니다.
    *   **예시:**
        *   **'아이언맨' (기술 분석 에이전트):** 기술 사양 분석, 벤치마크 DB 조회.
        *   **'블랙 위도우' (시장 반응 분석 에이전트):** 소셜 미디어, 뉴스 기사 등 여론 분석.
        *   **'닥터 스트레인지' (보고서 작성 에이전트):** 여러 정보를 종합하여 보고서 작성.

<a id="sec-3-3-pros-cons"></a>

### 멀티 에이전트의 장점과 과제

*   **장점:**
    *   **모듈성 및 확장성:** 각 에이전트가 독립적으로 개발, 유지보수될 수 있으며, 새로운 기능이 필요할 때 해당 전문가 에이전트를 추가하기 용이합니다.
    *   **효율성:** 복잡한 작업을 병렬로 처리하여 전체 소요 시간을 단축할 수 있습니다.
    *   **전문성:** 각 에이전트가 특정 작업에 최적화되어 더 높은 품질의 결과를 도출할 수 있습니다.
*   **과제:**
    *   **복잡성 증가:** 전체 시스템의 설계와 에이전트 간의 상호작용을 관리하는 것이 복잡합니다.
    *   **통신 오버헤드:** 에이전트 간의 통신 비용이 성능에 영향을 줄 수 있습니다.
    *   **오류 전파:** 한 에이전트의 실패가 다른 에이전트나 전체 시스템에 영향을 미칠 수 있습니다.

<a id="sec-3-4"></a>

### 3.4 Master Agent vs Specialized Agents

Multi-Agent 시스템에서 핵심은 **역할 분담**입니다. 마치 오케스트라에서 지휘자와 연주자들의 관계처럼, **Master Agent**가 전체를 조율하고 **Specialized Agents**가 각자의 전문 분야를 담당합니다.

#### Master Agent의 역할

```python
# ChatService (services/chat_service.py:118) - Master Agent 역할
class ChatService:
    async def handle(self, message: str, conversation_id: Optional[str] = None):
        # 1. 모드 결정 (룰 기반 vs 에이전트 기반)
        if llm_service.is_enabled():
            return await self._agentic_run(message, session_id)  # 에이전트 파이프라인
        else:
            return await self._rule_based_run(message, session_id)  # 룰 기반 폴백
            
    async def _agentic_run(self, message: str, session_id: str):
        # 2. Specialized Agents 순차 실행 및 조율
        analysis = IntentClassifier(llm_chat_fn=llm_service.chat).analyze_intent(message)
        plan = TaskPlannerAgent(llm_chat_fn=llm_service.chat).plan(message, analysis)
        observations = await ToolExecutor().execute_plan(plan, fill_args_fn, replan_fn)
        
        # 3. 최종 답변 생성 및 후처리
        final_answer = llm_service.chat(self._final_answer_prompt(observations))
        return self._postprocess_answer(final_answer, observations)
```

**Master Agent의 책임:**
- 🎯 **전략 결정**: 어떤 방식으로 처리할지 (룰 vs 에이전트)
- 🔀 **워크플로 조율**: Specialized Agents 실행 순서 관리
- 🔄 **오류 복구**: 한 에이전트 실패 시 대체 전략 실행
- 📝 **결과 통합**: 각 에이전트 결과를 최종 답변으로 조합

#### Specialized Agents의 역할

| **에이전트** | **전문 분야** | **입력** | **출력** |
|-------------|-------------|---------|----------|
| **IntentClassifier** | 의도 분류 & 라우팅 | 자연어 쿼리 | `{"intent": "weather_query", "apis": ["weather", "notification"]}` |
| **TaskPlannerAgent** | 계획 수립 & 재계획 | 의도 + API 후보 | `{"tasks": [{"id": "t1", "tool": "weather.forecast", "depends_on": []}]}` |
| **ToolExecutor** | 실행 & 최적화 | 태스크 그래프 | `{"observations": [...], "used_tools": [...]}` |

**각 에이전트의 특징:**
- ✅ **단일 책임**: 각자 하나의 전문 분야만 담당
- 🔄 **재사용 가능**: 다른 시스템에서도 활용 가능
- 🧪 **테스트 용이**: 독립적으로 테스트 가능
- 📈 **확장 가능**: 새 에이전트 추가 시 기존 에이전트 영향 없음

#### 실제 협업 예시

```python
# "다음 주 날씨 예보를 파일로 만들어서 팀에게 공유해줘"

# 1. Master Agent: 전체 흐름 시작
chat_service = ChatService()

# 2. IntentClassifier: 의도 분석
intent_result = {
    "intent": "weather_query",
    "apis": ["weather", "file", "notification"],  # 복합 요청 감지
    "confidence": 0.85
}

# 3. TaskPlannerAgent: 실행 계획 수립  
plan_result = {
    "tasks": [
        {"id": "t1", "tool": "weather.forecast", "args": {"city": "서울"}},
        {"id": "t2", "tool": "file.create", "args": {"name": "weather_report.md"}, "depends_on": ["t1"]},
        {"id": "t3", "tool": "notification.send", "args": {"message": "날씨 보고서"}, "depends_on": ["t2"]}
    ]
}

# 4. ToolExecutor: 계획 실행
execution_result = {
    "observations": [
        {"tool": "weather.forecast", "result": {"forecasts": [...]}},
        {"tool": "file.create", "result": {"file_id": "report_123"}},
        {"tool": "notification.send", "result": {"status": "sent", "id": "notif_456"}}
    ],
    "used_tools": ["weather.forecast", "file.create", "notification.send"]
}

# 5. Master Agent: 최종 답변 생성
final_answer = "다음 주 서울 날씨 예보 보고서를 생성하고 팀에게 공유했습니다."
```

<a id="sec-3-5"></a>

### 3.5 Function Calling 구현 패턴

Function Calling은 **LLM이 외부 도구를 호출할 수 있게 하는 핵심 메커니즘**입니다. 우리 구현에서는 FastMCP의 `@mcp.tool` 역할을 `DEFAULT_TOOL_SPECS`가 담당합니다.

#### Tool Registry 설계

```python
# services/tool_executor.py:21 - 우리의 "Function Calling 레지스트리"
DEFAULT_TOOL_SPECS: List[Dict[str, Any]] = [
    {
        "name": "weather.forecast",
        "description": "특정 도시의 일주일 날씨 예보를 조회한다.",
        "args_schema": {"city": "string (e.g., 서울)"},
        "ttl": 600  # 10분 캐시
    },
    {
        "name": "file.create", 
        "description": "새 파일을 생성한다.",
        "args_schema": {"name": "string", "content": "string", "path": "string"},
        "ttl": None  # 캐시 안함
    },
    # ... 19개 도구
]

def tools_prompt(tool_specs: Optional[List[Dict[str, Any]]] = None) -> str:
    """LLM에게 보여줄 도구 목록 문자열 생성 (FastMCP tool list와 유사)"""
    specs = tool_specs or DEFAULT_TOOL_SPECS
    return "\n".join([
        f"- {t['name']}: {t.get('description','')} | args={t.get('args_schema',{})}" 
        for t in specs
    ])
```

#### LLM-Tool 인터페이스 

```python
# TaskPlannerAgent가 도구 선택하는 과정
def plan(self, *, user_input: str, intent: str, apis: List[str], recent_turns: List[Dict]):
    prompt = f"""당신은 태스크 플래너 에이전트입니다.
목표: 사용자 요청을 실행 가능한 서브태스크로 분해하세요.

사용 가능한 도구:
{self.tools_prompt}  # ← 19개 도구 목록

반환 형식(키 고정):
{{"tasks":[{{"id":"t1","text":"...","tool":"weather.get|file.create|notification.send|none","args":{{...}},"depends_on":["t0"],"produces":"짧게"}}], "final_step":"tN"}}

사용자 요청: {user_input}"""
    
    return self.llm_chat_fn(prompt)  # LLM이 JSON 계획 생성
```

#### 인자 검증 및 보완

```python
# ToolExecutor에서 부족한 인자를 LLM이 자동 보완
async def execute_plan(self, tasks: List[Dict], fill_args_fn, replan_fn):
    for task in tasks:
        tool = task.get("tool")
        args = task.get("args") or {}
        
        # 인자가 부족하면 LLM에게 요청해서 채움
        if not args:
            args = fill_args_fn(tool, self.tool_schema(tool), observations) or {}
        
        # 도구 실행
        try:
            result = await self.call_tool(client, tool, args)
            observations.append({"tool": tool, "args": args, "result": result})
        except Exception as e:
            # 실행 실패 시 재계획 트리거
            if replan_fn:
                new_tasks = replan_fn(current_tasks, observations)
                if new_tasks:
                    current_tasks = new_tasks  # 새 계획으로 교체
```

#### FastMCP vs 우리 구현 비교

| **FastMCP** | **우리 구현** | **장점** |
|-------------|---------------|----------|
| `@mcp.tool` 데코레이터 | `DEFAULT_TOOL_SPECS` 리스트 | ✅ 명시적 스키마 정의 |
| 자동 함수 등록 | 수동 레지스트리 관리 | ✅ 세밀한 제어 가능 |
| MCP 프로토콜 | HTTP API 호출 | ✅ 마이크로서비스 호환 |
| 프레임워크 의존 | 순수 구현 | ✅ 학습 목적에 최적 |

<a id="sec-3-6"></a>

### 3.6 프롬프트 엔지니어링 실전

Agentic RAG에서 **프롬프트 엔지니어링**이 성공의 핵심입니다. 각 에이전트가 정확한 결과를 내기 위해서는 **명확하고 구조화된 프롬프트**가 필요합니다.

#### Few-shot Learning 활용

**IntentClassifier의 Few-shot 프롬프트 예시:**

```python
# agents/intent_classifier.py:71
prompt = f"""사용자 입력의 의도를 빠르게 분류하세요. (도메인 라우팅용)

분류 기준:
- weather_query: 날씨 관련 조회
- calendar_query: 일정 조회  
- calendar_create: 일정 생성
- file_search: 문서/파일 검색
- notification_send: 알림/공지 발송
- help: 도움말/기능 설명
- chat: 일반 대화/질문

예시:
"서울 날씨 어때?" → weather_query
"오늘 일정 있어?" → calendar_query  
"3시에 회의 잡아줘" → calendar_create
"계약서 찾아줘" → file_search
"팀에게 알려줘" → notification_send
"뭐 할 수 있어?" → help
"안녕하세요" → chat
"우리 회사 매출이 얼마야?" → chat
"비가 올까?" → weather_query
"내일 미팅 있나?" → calendar_query

사용자 입력: "{user_input}"
분류 결과 (intent만 답변): """
```

**Few-shot의 핵심 원칙:**
1. **명확한 분류 기준** 제시
2. **다양한 예시** 포함 (긍정/부정 사례)  
3. **일관된 출력 형식** 강제
4. **엣지 케이스** 처리 ("비가 올까?" → weather_query)

#### JSON 출력 강제하기

**TaskPlannerAgent의 구조화된 출력:**

```python
# agents/task_planner_agent.py:56
def plan(self, *, user_input: str, intent: str, apis: List[str], recent_turns: List[Dict[str, Any]]) -> Dict[str, Any]:
    prompt = (
        "당신은 태스크 플래너 에이전트입니다.\n"
        "목표: 사용자 요청을 실행 가능한 서브태스크로 분해하고, 각 태스크의 실행 순서/의존성을 포함한 계획을 JSON으로 작성하세요.\n"
        "반드시 JSON만 출력.\n\n"
        "사용 가능한 도구:\n"
        f"{self.tools_prompt}\n\n"
        f"의도(intent): {intent}\n"
        f"API 후보: {apis}\n\n"
        f"최근 대화(참고): {_safe_str(recent_turns, 800)}\n\n"
        "반환 형식(키 고정):\n"
        '{ "tasks":[{"id":"t1","text":"...","tool":"weather.get|...|none","args":{...},"depends_on":["t0"],"produces":"짧게"}], "final_step":"tN" }\n\n'
        "규칙:\n"
        "- tool이 필요 없으면 \"none\"\n"
        "- args는 가능한 채워서 주고, 불확실하면 비워두고 실행기(Executor)가 채우게 하세요.\n"
        "- depends_on은 task id 리스트\n\n"
        f"사용자 요청: {user_input}\n"
    )
    return _extract_json_object(self.llm_chat_fn(prompt))
```

**JSON 출력 강제 기법:**
1. **"반드시 JSON만 출력"** 명시적 지시
2. **정확한 스키마** 예시 제공
3. **키 고정** 요구 (`"tasks"`, `"final_step"`)
4. **구조 검증** 후처리 (`_extract_json_object`)

#### 재계획 프롬프트 설계

**실행 중 관찰 결과를 반영한 동적 재계획:**

```python
# agents/task_planner_agent.py:76
def replan(self, *, user_input: str, intent: str, apis: List[str], 
          current_tasks: List[Dict[str, Any]], observations: List[Dict[str, Any]]) -> Dict[str, Any]:
    prompt = (
        "당신은 태스크 플래너 에이전트입니다. 실행 중 관찰 결과를 반영해 계획을 업데이트하세요.\n"
        "반드시 JSON만 출력.\n\n"
        "사용 가능한 도구:\n"
        f"{self.tools_prompt}\n\n"
        f"의도(intent): {intent}\n"
        f"API 후보: {apis}\n\n"
        f"현재 계획(tasks): {_safe_str(current_tasks, 1400)}\n\n"
        f"관찰(observations): {_safe_str(observations, 1400)}\n\n"  # ← 실행 결과 피드백
        "반환 형식(키 고정):\n"
        '{ "tasks":[{"id":"t1","text":"...","tool":"...|none","args":{...},"depends_on":["..."],"produces":"..."}], "final_step":"tN" }\n\n'
        f"사용자 요청: {user_input}\n"
    )
    return _extract_json_object(self.llm_chat_fn(prompt))
```

#### 인자 보완 프롬프트

**부족한 도구 인자를 LLM이 자동 추론:**

```python
# services/chat_service.py:475
def _agentic_fill_args_prompt(self, *, user_input: str, tool: str, args_schema: Dict[str, Any], 
                              recent_turns: List[Dict[str, Any]], observations: List[Dict[str, Any]]) -> str:
    return (
        "당신은 Executor를 돕는 ReAct 서브루틴입니다.\n"
        "주어진 tool을 실행하기 위한 args만 JSON으로 채우세요. 반드시 JSON만 출력.\n\n"
        f"tool: {tool}\n"
        f"args_schema: {args_schema}\n"
        f"최근 대화(참고): {_safe(recent_turns)}\n\n"
        f"이전 관찰(observations, 참고): {_safe(observations)}\n\n"  # ← 이전 실행 결과 활용
        f"사용자 요청: {user_input}\n"
        '반환 형식: {"args":{...}}\n'
    )
```

#### 최종 답변 생성 프롬프트

**실행 관찰 결과를 자연어 답변으로 변환:**

```python
# services/chat_service.py:503
def _agentic_final_answer_prompt(self, *, user_input: str, intent: str, 
                                tasks: List[Dict[str, Any]], observations: List[Dict[str, Any]]) -> str:
    return (
        "당신은 Assistant입니다. 실행 관찰 결과를 바탕으로 사용자에게 최종 답변을 생성하세요.\n"
        "불필요한 내부 계획/JSON/디버그를 노출하지 말고, 자연어로 간결하게 답하세요.\n\n"
        "규칙:\n"
        "- `rag.query` 관찰에 hits/source가 있으면, 답변 마지막에 **근거(출처)** 를 1~3개 bullet로 반드시 포함하세요.\n"
        "- 사용자가 '공유/알려줘/슬랙' 등을 요청했고 `notification.send` 관찰이 있으면, '슬랙 공유 완료'를 함께 안내하세요.\n\n"
        f"Intent: {intent}\n"
        f"사용자 요청: {user_input}\n\n"
        f"계획(tasks): {_safe(tasks, 1200)}\n\n"
        f"관찰(observations): {_safe(observations, 1800)}\n"  # ← 모든 실행 결과 종합
    )
```

#### 프롬프트 최적화 팁

| **문제** | **해결책** | **예시** |
|----------|-----------|----------|
| **JSON 파싱 실패** | 스키마 예시 + "반드시 JSON만" | `'{ "tasks": [...] }'` |
| **일관성 없는 출력** | Few-shot 예시 다양화 | 긍정/부정 사례 모두 포함 |
| **컨텍스트 오버플로우** | 중요도별 내용 제한 | `_safe_str(data, limit=800)` |
| **환각(Hallucination)** | 도구 목록 명시적 제공 | `tools_prompt()` 포함 |
| **재계획 실패** | 이전 관찰 결과 피드백 | `observations` 활용 |

---

<a id="chapter-4"></a>

# Chapter 4: Agentic RAG 실전 구현 (코드 중심)

> **Note:** 이 챕터는 실습 코드 리뷰와 시연 중심으로 진행됩니다. 사전에 작성된 코드를 함께 살펴보며 실제 구현 방법을 학습합니다.

<a id="sec-4-1"></a>

## 4.1 구현 아키텍처 개요

<a id="sec-4-1-diagram"></a>

### 시스템 구성도

```
사용자 질문
    ↓
Chat API (FastAPI: chatbot-service)
    ↓
ChatService (`services/chat_service.py`) ← Multi-Agent 오케스트레이션
    ↓
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│ IntentClassifier │ → │ TaskPlannerAgent │ → │ ToolExecutor    │
│ (의도 분류 에이전트) │   │ (계획 수립 에이전트) │   │ (실행 에이전트)   │
│ Few-shot LLM    │    │ Plan/Replan    │    │ Execute + Cache │
└─────────────────┘    └─────────────────┘    └─────────────────┘
                                                       ↓
       ┌──────────┬───────────┬──────────┬──────────────────┬──────────┐
       ↓          ↓           ↓          ↓                  ↓          ↓
   weather    calendar     file      notification        rag       (19개 도구)
   (8001)     (8002)      (8003)      (8004)           (8005)
       ↓
최종 답변 생성 (+ 근거/출처 + 알림결과 + 세션 캐시)
```

<a id="sec-4-1-components"></a>

### 핵심 컴포넌트

1.  **ChatService (Master Agent)** - 비즈니스 로직 & Multi-Agent 조합
    *   파일: `chatbot-service/services/chat_service.py`
    *   역할: 룰 기반 ↔ 에이전트 모드 전환, 전체 실행 흐름 관리
    *   LLM 설정: `chatbot-service/services/llm_service.py` + `config.yml` + `.env`

2.  **Multi-Agent 파이프라인 (3개 전문 에이전트)**
    *   **IntentClassifier** (`agents/intent_classifier.py`): Few-shot LLM 기반 의도 분류, 빠른 라우팅 결정
    *   **TaskPlannerAgent** (`agents/task_planner_agent.py`): 복잡한 쿼리를 실행 가능한 서브태스크로 분해, 동적 재계획
    *   **ToolExecutor** (`services/tool_executor.py`): 19개 도구 실행 + 세션 캐시 + ReAct 패턴

3.  **Tool Registry (19개 도구 = 마이크로서비스 API)**
    *   **Weather** (3개): `weather.get`, `weather.forecast`, `weather.cities`
    *   **Calendar** (5개): `calendar.get`, `calendar.get_date`, `calendar.create`, `calendar.free_time`, `calendar.summary`
    *   **File** (6개): `file.search`, `file.get`, `file.content`, `file.list`, `file.directories`, `file.create`
    *   **Notification** (4개): `notification.send`, `notification.history`, `notification.stats`, `notification.get`
    *   **RAG** (1개): `rag.query` (Qdrant 백엔드 필요)

4.  **컨텍스트 & 캐싱**
    *   대화 컨텍스트: `chatbot-service/agents/context_manager.py` (세션 관리 + 툴 결과 캐시)
    *   TTL 기반 캐싱으로 중복 API 호출 방지 및 성능 최적화

<a id="sec-4-2"></a>

## 4.2 각 에이전트 상세 분석

이제 우리 Multi-Agent 시스템의 **3개 전문화된 에이전트**와 **1개 마스터 에이전트**를 구현 레벨에서 상세히 분석해보겠습니다.

<a id="sec-4-2-1"></a>

### 4.2.1 ChatService (Master Agent) (`services/chat_service.py`)

**역할:** 전체 Multi-Agent 파이프라인 오케스트레이션 및 최종 응답 생성

#### 핵심 구현 포인트

```python
# services/chat_service.py - Master Agent의 Multi-Agent 조율
async def handle(self, *, message: str, conversation_id: str = None, conversation_history = None):
    session_id = get_or_create_session(conversation_id)
    
    # 1. 의도 분석 (IntentClassifier)
    intent_result = await self.intent_classifier.analyze_intent(...)
    
    # 2. 태스크 계획 (TaskPlannerAgent)  
    plan_result = await self.task_planner.plan(...)
    
    # 3. 도구 실행 (ToolExecutor)
    observations, used_tools, final_tasks = await self.tool_executor.execute_plan(...)
    
    # 4. 최종 응답 합성
    final_response = await self._synthesize_response(...)
```

**마스터 에이전트의 책임:**

1.  **Agent Coordination**: 3개 전문 에이전트 순차 호출 및 데이터 전달
2.  **Context Management**: 세션별 대화 이력 및 도구 캐시 관리
3.  **Error Recovery**: 각 단계 실패 시 적절한 복구 전략 실행 (`replan_fn`)
4.  **Response Synthesis**: 관찰 결과를 자연어로 종합하여 최종 답변 생성

#### 실행 모드 전환

```python
# Rule-based vs Agentic 모드 자동 전환
if self._is_simple_request(intent_result["intent"]):
    # Rule-based: 단순 날씨/일정 조회 등
    return await self._handle_simple_request(message, intent_result)
else:
    # Agentic: 복잡한 추론/계획이 필요한 요청
    return await self._handle_complex_request(message, intent_result, plan_result)
```

<a id="sec-4-2-2"></a>

### 4.2.2 IntentClassifier Agent (`agents/intent_classifier.py`)

**역할:** 사용자 입력을 분석하여 의도를 분류하고 적절한 처리 전략(API 후보)을 결정합니다.

#### 핵심 구현 포인트

```python
# agents/intent_classifier.py:45 - Few-shot Learning 기반 분류
class IntentClassifier:
    async def analyze_intent(self, *, user_input: str, conversation_history: List[Dict]) -> Dict[str, Any]:
        # 1. Few-shot 예시 10개로 패턴 학습
        few_shot_examples = [
            {"input": "내일 서울 날씨 어때?", "intent": "weather_query", ...},
            # ... 총 10개 예시
        ]
        
        # 2. LLM 기반 의도 분류 (JSON 강제 출력)
        prompt = self._build_few_shot_prompt(user_input, few_shot_examples)
        result = await self.llm_service.generate(prompt, force_json=True)
```

**기술적 특징:**

1.  **Composite Request 감지**: "날씨 확인하고 일정 만들어줘" 같은 복합 요청을 감지하고 `sub_intents`를 추출합니다.
2.  **Fallback 메커니즘**: LLM 비활성화 시 키워드 기반 분류로 자동 전환됩니다.
3.  **Context-Aware**: 대화 이력을 반영하여 보다 정확한 의도를 분석합니다.

<a id="sec-4-2-3"></a>

### 4.2.3 TaskPlannerAgent (`agents/task_planner_agent.py`)

**역할:** 분류된 의도를 바탕으로, 실행 가능한 서브태스크들의 DAG(Directed Acyclic Graph)를 생성합니다.

#### 핵심 구현 포인트

```python
# agents/task_planner_agent.py:87 - Dynamic Planning with ReAct
async def plan(self, *, user_input: str, intent: str, apis: List[str], recent_turns: List[Dict]):
    # 1. 사용 가능한 도구 목록 확인 (19개)
    available_tools = self.tools_prompt
    
    # 2. ReAct 프롬프트로 계획 생성 요청
    planning_prompt = f"""...
사용 가능한 도구: {available_tools}
의도: {intent}
사용자 입력: {user_input}
반환 형식(키 고정): {{"tasks":[...], "final_step":"tN"}}
"""

    # 3. JSON 강제 출력으로 구조화된 계획 생성
    result = await self.llm_service.generate(planning_prompt, force_json=True)
```

**계획 품질 향상 기법:**

1.  **Dependency Tracking**: 태스크 간 `depends_on` 관계를 명시하여 실행 순서를 보장합니다.
2.  **Tool Selection**: 19개 도구 중 현재 요청에 가장 적합한 조합을 선택합니다.
3.  **Error Recovery**: 실행 실패 시 `replan` 함수를 통해 동적으로 계획을 수정합니다.

<a id="sec-4-2-4"></a>

### 4.2.4 ToolExecutor (`services/tool_executor.py`)

**역할:** 계획된 도구를 순차/병렬 실행하고, 결과를 캐싱하며, 모든 실행 과정을 `observations`로 기록합니다.

#### 핵심 구현 포인트

```python
# services/tool_executor.py:228 - Session-based Execution with Caching
async def execute_plan(self, *, tasks: List[Dict], ...):
    observations: List[Dict[str, Any]] = []
    
    # DAG(위상 정렬)에 따라 태스크 실행
    for task in self._sort_by_dependencies(tasks):
        # 1. 세션 기반 캐시 확인
        cached = context_manager.get_cached_tool_result(session_id, cache_key, ttl)
        if cached:
            # 캐시된 결과 사용
        else:
            # 2. 실제 도구(API) 실행
            result = await self.call_tool(client, tool, args)
            context_manager.set_cached_tool_result(...) # 결과 캐싱
```

**성능 최적화 기법:**

1.  **TTL 기반 캐싱**: 도구별로 다른 캐시 유효기간(TTL)을 설정합니다. (e.g., 날씨 10분, 일정 1분)
2.  **Parallel Execution**: 의존성이 없는 도구는 `asyncio.gather`를 통해 병렬 실행이 가능합니다.
3.  **Error Handling**: 개별 도구 실행 실패가 전체 계획을 중단시키지 않도록 예외 처리 및 재계획을 트리거합니다.

<a id="sec-4-3"></a>

## 4.3 Multi-Agent 실행 흐름 Deep Dive

앞서 분석한 에이전트들이 실제로 어떻게 협력하는지 구체적인 요청을 통해 따라가 보겠습니다.

**예시 요청**: "Agentic RAG가 뭐야? 강의자료에서 근거를 찾아서 요약하고, 팀에게 슬랙으로 공유해줘"

<a id="sec-4-3-step-1"></a>

### Step 1: IntentClassifier (의도 분류)

-   **입력**: "Agentic RAG가 뭐야? ... 슬랙으로 공유해줘"
-   **출력**: `{"intent": "rag_query", "apis": ["rag", "notification"], "confidence": 0.9}`
-   **판단**: `rag.query`와 `notification.send` 도구가 필요하다고 식별합니다.

<a id="sec-4-3-step-2"></a>

### Step 2: TaskPlannerAgent (계획 수립)

-   **입력**: `intent`, `apis`
-   **출력 (계획)**:
    ```json
    {
        "tasks": [
            {"id": "t1", "tool": "rag.query", "args": {"query": "Agentic RAG 정의"}, "text": "Agentic RAG 정의 검색"},
            {"id": "t2", "tool": "notification.send", "args": {"message": "{t1.result} 요약"}, "depends_on": ["t1"], "text": "검색 결과를 요약하여 팀에게 공유"}
        ]
    }
    ```
-   **판단**: `rag.query`를 먼저 실행하고, 그 결과를 `notification.send`의 인자로 사용해야 함을 `depends_on`으로 명시합니다.

<a id="sec-4-3-step-3"></a>

### Step 3: ToolExecutor (실행 및 관찰)

1.  **t1 실행**: `rag.query` 호출 → `[Observation 1]` (문서 검색 결과) 생성
2.  **t2 실행**: `notification.send` 호출 → `[Observation 2]` (알림 발송 성공) 생성

<a id="sec-4-3-step-4"></a>

### Step 4: ChatService (최종 답변 종합)

-   **입력**: `[Observation 1]`, `[Observation 2]`
-   **출력 (최종 답변)**:
    > "Agentic RAG는 RAG를 에이전트가 필요할 때 사용하는 도구로 보는 방식입니다... (중략)
    >
    > **[슬랙 공유 완료]** 팀 채널에 요약을 전송했습니다."

<a id="sec-4-3-insights"></a>

### 핵심 인사이트

-   에이전트가 스스로 “RAG 검색이 필요한지 / 알림 전송이 필요한지”를 판단하고 tool을 조합합니다.
-   고정된 파이프라인이 아닌 **동적 의사결정**으로 복잡한 문제를 해결합니다.
-   `depends_on`을 이용한 태스크 의존성 관리가 Multi-Agent 협업의 핵심입니다.

<a id="sec-4-4"></a>

## 4.4 코드 리뷰: 주요 구현 포인트

<a id="sec-4-4-1"></a>

### 4.4.1 벡터 DB 연결 및 RAG 도구 구성

**핵심 코드 스니펫:**

```python
"""
이 레포의 실습 구현은 LangChain을 직접 쓰지 않고,
`rag-service`(8005) + `shared_utils.py/QdrantUtils`로 RAG를 제공합니다.
"""

# chatbot-service/services/tool_executor.py
# 'rag.query' 도구가 호출되면 내부적으로 rag-service API를 호출합니다.

async def call_tool(self, tool_name: str, args: Dict) -> Any:
    if tool_name == "rag.query":
        # http://localhost:8005/rag/query 로 POST 요청
        response = await client.post(f"{self.rag_service_url}/query", json=args)
        return response.json()
```

**주요 포인트:**
*   이 프로젝트에서 RAG는 **별도 마이크로서비스**(`rag-service`)로 제공됩니다.
*   에이전트 관점에서는 `rag.query`라는 하나의 도구로 추상화되어 노출됩니다.

<a id="sec-4-4-2"></a>

### 4.4.2 에이전트 생성 및 실행

**(실습 코드) `chatbot-service` 기반 에이전트 실행 흐름:**

```python
"""
요약:
- API 진입: chatbot-service/api/chat.py
- Master Agent: chatbot-service/services/chat_service.py
  - IntentClassifier -> TaskPlannerAgent(plan/replan) -> ToolExecutor(execute+cache)
"""

# services/chat_service.py의 handle 메서드가 모든 것을 조율합니다.
class ChatService:
    def __init__(self):
        self.intent_classifier = IntentClassifier()
        self.task_planner = TaskPlannerAgent()
        self.tool_executor = ToolExecutor()
        # ...

    async def handle(self, message: str, ...):
        # ... (위에서 설명한 Step 1~4 실행) ...
        return final_response
```

<a id="chapter-5"></a>

# Chapter 5: 실전 활용 및 최적화

> **Note:** 프로덕션 환경 배포와 성능 최적화를 다룹니다.

<a id="sec-5-1"></a>

## 5.1 성능 최적화 전략

<a id="sec-5-1-1"></a>

### 5.1.1 LLM 토큰 비용 관리

**비용 구조 (OpenAI 기준, 2024년)**

| 모델 | 입력 (1M 토큰) | 출력 (1M 토큰) | 적합한 사용처 |
| :--- | :--- | :--- | :--- |
| GPT-4 Turbo | $10 | $30 | 복잡한 추론, 고품질 요구 |
| GPT-4o-mini | $0.15 | $0.60 | 일반적인 RAG, 에이전트 (가성비) |
| GPT-3.5-turbo | $0.50 | $1.50 | 단순 작업, 프로토타입 |

**비용 절감 기법:**

1.  **프롬프트 압축**
    *   불필요한 예시, 설명 제거
    *   "당신은 최고의 AI 어시스턴트입니다..." → "AI 어시스턴트:"

2.  **컨텍스트 윈도우 최적화**
    *   검색 결과 K=5 → K=3으로 줄이기 (품질 vs 비용 트레이드오프)
    *   Re-ranking으로 정확도 유지하면서 전달 문서 최소화

3.  **캐싱 활용**
    *   동일 질문 반복 시 이전 답변 재사용
    *   Redis, Memcached로 LLM 응답 캐싱

4.  **모델 다운그레이드**
    *   단순 분류 - role base, 라우팅: GPT-4o-mini
    *   복잡한 추론: GPT-4 Turbo

<a id="sec-5-1-2"></a>

### 5.1.2 응답 속도 향상

**병목 지점 분석:**

| 단계 | 평균 소요 시간 | 최적화 방법 |
| :--- | :--- | :--- |
| 벡터 검색 | 10~50ms | ANN 알고리즘 최적화 (HNSW) |
| LLM 호출 | 1~5초 | 스트리밍, 병렬 처리 |
| Re-ranking | 100~500ms | GPU 사용, 배치 처리 |
| 전체 파이프라인 | 2~8초 | 병렬화, 캐싱 |


<a id="sec-5-1-3"></a>

### 5.1.3 검색 품질 개선

검색 품질을 40% → 70%까지 올리는 건 “구조를 갖춘 RAG”만 해도 가능하지만, **70% → 80~90%**는 대부분 **데이터/검색/랭킹/운영 루프**에서 디테일을 쌓아야 합니다. 아래는 프로덕션에서 체감 효과가 큰 개선 포인트들입니다.

---

<a id="sec-5-1-3-1"></a>

#### 1) 먼저 “문제가 어디서 생기는지”를 분해해서 본다 (에러 택소노미)

정확도가 안 나오는 원인을 크게 나누면 다음 중 하나(혹은 복합)입니다.

- **Recall 문제 (못 찾음)**: 검색 결과 상위 K에 “정답 문서/정답 청크” 자체가 없음  
- **Ranking 문제 (찾았는데 위에 안 뜸)**: K 안에는 있는데 순위가 낮아서 LLM이 못 씀
- **Context 문제 (찾았는데 못 씀)**: 청크가 너무 길/짧거나, 근거가 분산되어 답이 안 나옴
- **Answering 문제 (찾아줘도 답을 못함/환각)**: 프롬프트/모델/가드레일 문제

실무 팁:

- **Recall@K가 낮으면**: 임베딩/청킹/하이브리드/필터링 설계를 먼저 손봅니다.
- **Recall@K는 높은데 MRR/NDCG가 낮으면**: re-ranker(또는 쿼리 리라이트/확장) 쪽이 효율이 좋습니다.

---

<a id="sec-5-1-3-2"></a>

#### 2) 임베딩 모델 선택: “한국어”는 생각보다 함정이 많다

임베딩은 초기에 잘못 고르면 이후 모든 튜닝 비용이 커집니다.

- **언어 커버리지**: 한국어 문서라면 최소한 **한국어 최적화** 또는 **고품질 멀티링구얼**을 고려합니다.  
  - **중국계 멀티링구얼 모델**은 한국어 코퍼스를 많이 포함하는 경우가 있지만, 도메인(업무 용어/약어/사내 문체)을 “의미적으로” 잘 묶어주지 못하는 케이스가 잦습니다. 결국 “비즈니스 용어 맵핑”이 성능을 갈라요.
- **토크나이저/정규화 민감도**: 한국어는 띄어쓰기, 조사/어미, 표기 변형(영문 약어/숫자/단위)이 검색에 크게 영향을 줍니다.  
  - 예: “계약서상”, “계약서 상”, “계약서(상)”이 같은 의미라도 벡터 공간에서는 멀어질 수 있음
- **도메인 적합성**: 일반 임베딩이 잘 못 잡는 것들  
  - 사내 약어(예: “KPI”, “OKR”, “SLA”), 시스템 코드(에러코드), 제품명/프로젝트명, 정책/규정 문체

실무적으로는 다음 순서를 추천합니다.

- **(1) 전처리/정규화 → (2) 하이브리드 → (3) re-ranker → (4) 그래도 부족하면 임베딩 파인튜닝**

임베딩을 곧바로 파인튜닝하는 건 비용 대비 실패 확률이 높습니다(학습 데이터/하드 네거티브가 없으면 특히).

---

<a id="sec-5-1-3-3"></a>

#### 3) 임베딩 파인튜닝을 “언제” 하는가 (그리고 무엇이 데이터가 되는가)

임베딩 파인튜닝이 효과를 내는 전형적인 조건:

- **도메인 용어가 일반 의미와 다르게 쓰임** (예: “배포”, “정산”, “승인” 등 사내 프로세스 의미)
- **쿼리가 짧고 모호** (사용자들이 “그거 어떻게 하지?” 식으로 물어봄)
- **문서 구조가 복잡** (정답이 한 문서 내 여러 구간에 분산)

데이터 소스(현실적인 것부터):

- **검색 로그 기반 weak supervision**: 사용자가 클릭/스크롤/체류한 문서(청크)를 positive로, 노출됐지만 무시된 것을 negative로
- **Q/A 쌍**: 고객지원/헬프데스크/사내 질문 게시판
- **규정/정책 문서에서 생성한 쿼리**: 섹션 제목/요약문/용어집을 쿼리로 사용 (다만 “너무 교과서적인 질문”만 만들지 않도록 주의)

학습 팁:

- **Hard negative(헷갈리는 오답)**를 넣지 않으면 파인튜닝 효과가 급감합니다.  
  - 같은 문서 내 다른 섹션, 유사 용어(예: “정산” vs “환불정산”), 유사 프로세스(“승인” vs “검토”)를 네거티브로 구성

---

<a id="sec-5-1-3-4"></a>

#### 4) Chunking(청킹)이 실제로 성능을 좌우한다

청킹은 “길이” 문제가 아니라 “정답 근거가 한 덩어리로 존재하느냐” 문제입니다.

- **고정 토큰 청킹의 한계**: 표/리스트/절(조항) 구조가 깨지면 검색은 되는데 답이 안 나옵니다.
- **권장 전략**  
  - **구조 기반 청킹**: 문서의 제목/소제목/목록/표를 기준으로 의미 단위로 쪼갬  
  - **Overlap**: 10~20% 정도의 겹침을 두어 경계 손실을 줄임  
  - **Hierarchical chunk**: 작은 청크(정밀) + 큰 청크(맥락) 2레벨을 같이 저장하거나, re-ranker 단계에서 큰 맥락을 합쳐줌
- **한국어 팁**: “정의/조건/예외/절차/주의사항” 같은 패턴은 한 청크에 묶이면 답변 품질이 크게 좋아집니다.

---

<a id="sec-5-1-3-5"></a>

#### 5) 하이브리드 검색은 “정확도 상한”을 올려준다

앞서 `3.1.1 하이브리드 검색`에서 그 원리를 설명했듯이, 이 기법은 벡터 검색만으로는 한계가 있는 **키워드/코드/고유명사** 검색을 보완하여 정확도의 상한선을 높여줍니다. 프로덕션에서 80% 이상의 정확도를 목표할 때 특히 중요합니다.

- **BM25(키워드) + Vector(의미) 결합**은 특히 다음에서 강합니다.
  - 제품명/프로젝트명/에러코드/약관 조항 번호/정확한 문자열
  - “A가 아닌 B”처럼 부정/대비가 있는 질의(벡터가 뭉개기 쉬움)
- 튜닝 포인트:
  - **가중치(예: 40/60)** 자체보다, **필터링(메타데이터) + re-ranker**까지 합쳐진 파이프라인이 성능을 결정합니다.

---

<a id="sec-5-1-3-6"></a>

#### 6) Query 전처리: “사용자가 던지는 질문”을 검색 가능한 형태로 바꾼다

사람이 하는 질문은 검색 친화적이지 않습니다. 아래는 체감 개선이 큰 기법들입니다.

- **Query rewriting (의도 보존 재작성)**  
  - 짧고 구어체인 질문을 “정확한 키워드/용어”가 포함되도록 재작성  
  - 예: “이거 결재는 어떻게 올려요?” → “사내 결재 상신 절차 / 결재선 설정 / 결재 반려 처리”
- **Query expansion (동의어/약어 확장)**  
  - “휴가” ↔ “연차”, “반차”, “휴무”, “PTO”  
  - 사내 용어집이 있으면 가장 효과적인 투자처입니다.
- **언어 전략 (교착어인 한국어/중국어 vs 영어)**  
  - 많은 LLM은 **지시문(instruction)을 영어로 쓸 때** 더 안정적인 경우가 있습니다.  
  - 실무 패턴: **시스템 프롬프트/규칙은 영어**, **유저 입력/답변은 한국어**, **검색 쿼리는 한국어+영어 병행 생성**  
    - 예: 쿼리를 2개 만들어서(ko/en) 벡터 검색을 병렬로 돌리고 합치는 방식

---

<a id="sec-5-1-3-7"></a>

#### 7) Re-ranker는 “랭킹의 마지막 10~20%”를 올리는 가장 강력한 레버

`3.1.2 Re-ranking`에서 설명한 2단계 검색 구조의 핵심인 Re-ranker는, 특히 랭킹의 마지막 10~20% 정확도를 끌어올리는 가장 강력한 레버입니다. `3.1.2 Re-ranking`에서 설명한 2단계 검색 구조의 핵심인 Re-ranker는, 특히 랭킹의 마지막 10~20% 정확도를 끌어올리는 가장 강력한 레버입니다. re-ranker는 보통 **Cross-Encoder(쿼리-문서 쌍을 같이 읽는 모델)** 계열이 강합니다.

- **도입 효과가 큰 조건**: 상위 K에 정답이 자주 “있긴 한데” 순위가 낮을 때
- **비용/지연 고려**:
  - K를 너무 크게 잡으면 비용이 폭증하므로, **Retrieval K는 크게(예: 30~100), Re-rank K는 작게(예: 5~10)** 같이 “두 단계 K”를 분리하는 방식이 흔합니다.
- **re-ranker 파인튜닝**:
  - 임베딩 파인튜닝보다 **라벨링 난이도가 낮고**, 효과가 잘 나오는 편입니다.
  - 학습 데이터는 “쿼리-정답 청크(positive)”와 “유사하지만 오답 청크(hard negative)”가 핵심입니다.

---

<a id="sec-5-1-3-8"></a>

#### 8) 메타데이터/필터링: 정확도를 올리는 ‘숨은 치트키’

벡터 검색만으로는 “정답이 아닌데 의미가 비슷한 문서”가 계속 섞입니다. 이걸 줄이는 게 80% 이후의 핵심이에요.

- **문서 타입/시스템/부서/버전/유효기간** 같은 메타데이터를 payload로 저장
- 검색 시 **필터**로 후보군을 줄인 뒤 벡터/하이브리드 검색
- 특히 **정책/규정은 버전 관리**가 중요 (구버전이 섞이면 체감 정확도가 급락)

---

<a id="sec-5-1-3-9"></a>

#### 9) “정답률 90%”는 기능이 아니라 운영 체계다 (평가/모니터링/피드백 루프)

프로덕션에서 정확도는 고정된 숫자가 아니라 **데이터 드리프트**로 계속 흔들립니다.

- **오프라인 평가 세트(Golden set)**를 반드시 유지  
  - 신규 기능/문서 추가 시 Recall@K, MRR, NDCG를 지속 측정
- **온라인 지표**(대체지표라도) 확보  
  - 재질문율(“다시 물어봄”), 답변 수정율, 상담원 핸드오프율, 클릭/체류 기반 만족도
- **에러 분석 루프**  
  - “못 찾음 vs 찾았는데 못 씀 vs 환각”으로 분류해서 담당 레버(청킹/검색/리랭킹/프롬프트)를 다르게 튜닝

---

<a id="sec-5-1-3-10"></a>

#### 10) 현실 조언: 70% → 90% 구간에서 자주 하는 실수

- **모델만 바꾸면 해결될 거라 기대**: 대부분은 청킹/정규화/메타데이터/하이브리드/리랭킹에서 해결됩니다.
- **K를 무작정 키움**: Recall은 오르지만 컨텍스트가 오염되어 Answering이 망가지는 경우가 많습니다.
- **평가 세트 없이 “감”으로 튜닝**: 80% 이후는 작은 개선이 누적되는 구간이라, 지표 없이 하면 방향을 잃습니다.

**평가 지표 (Evaluation Metrics):**

*   **Recall@K:** 상위 K개 결과에 정답이 포함될 확률
*   **MRR (Mean Reciprocal Rank):** 정답이 몇 번째에 나타나는지
*   **NDCG (Normalized Discounted Cumulative Gain):** 순위를 고려한 정확도

**A/B 테스트:**
*   하이브리드 검색 (BM25 40% + Vector 60%) vs 순수 벡터 검색
*   Re-ranking 적용 여부
*   청크 크기 비교 (256 토큰 vs 512 토큰)

<a id="sec-5-1-resources"></a>

### 추천 리소스

**공식 문서:**
*   LangChain : https://python.langchain.com/docs
*   LangGraph : https://langchain-ai.github.io/langgraph/
*   Qdrant : https://qdrant.tech/documentation/

**이론 참고자료:**
*   KT DS 사내 강의 자료 : https://github.com/SeoJHeasdw/edu-ai-deep-dive-repo/blob/main/ai-basic/theory/ai-basic-lecture.md
**실전 프로젝트 아이디어:**
*   회사 내부 문서 Q&A 챗봇
*   고객 지원 자동화 시스템
*   법률/의료 도메인 전문가 AI
*   개인 지식 관리 AI (Second Brain)
