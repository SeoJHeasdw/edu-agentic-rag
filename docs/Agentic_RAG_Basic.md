# Chapter 1: RAG & Agent 기초 이해 (최종 버전)

## 1.1 RAG: 똑똑한 AI를 더 똑똑하고, 더 정확하게 만들기

### LLM은 '만능'이 아닙니다: 오픈북 시험이 필요한 이유

대규모 언어 모델(LLM)은 방대한 지식을 학습한 천재와 같습니다. 하지만 이 천재에게도 두 가지 약점이 있습니다.

1.  **오래된 기억 (Knowledge Cut-off):** 2023년에 학습이 끝난 모델에게 "2024년 최신 AI 트렌드는 뭐야?"라고 물으면, 대답할 수 없습니다.
2.  **그럴듯한 거짓말 (환각, Hallucination):** LLM은 모르는 것도 아는 척하며 그럴듯하게 지어내는 재주가 있습니다. "세종대왕이 맥북을 던진 사건에 대해 알려줘"라는 황당한 질문에도, 사실무근인 이야기를 만들어낼 수 있습니다.

이러한 문제를 해결하기 위해 **RAG(검색 증강 생성)**가 등장했습니다. RAG는 LLM을 **'오픈북 시험'**을 치르는 학생으로 만듭니다. 즉, LLM이 자신의 기억력에만 의존하지 않고, **신뢰할 수 있는 최신 자료(책)를 직접 찾아보고 그 내용을 근거로 답변**하게 만드는 기술입니다.

> **핵심 비유:**
> *   **LLM 단독 사용:** 암기한 내용으로만 시험 보는 '클로즈북 시험'
> *   **RAG 활용:** 교과서, 참고서를 마음껏 찾아보며 시험 보는 '오픈북 시험'

### RAG의 핵심 구성 요소와 작동 원리

RAG 시스템은 크게 **인덱싱(Indexing)**과 **검색 및 생성(Retrieval & Generation)** 두 단계로 나뉩니다.

#### 1단계: 인덱싱 (지식 도서관 구축)

LLM이 외부 지식을 빠르고 정확하게 참조할 수 있도록, 원본 문서를 미리 가공하여 '지식 창고'(Vector Store)를 구축하는 과정입니다.

1.  **데이터 로드 (Load):** 다양한 형태의 문서(PDF, TXT, HTML, DB 등)를 불러옵니다.
2.  **분할 (Split / Chunking):** 불러온 문서를 LLM이 한 번에 처리할 수 있는 크기의 의미 있는 단위(Chunk)로 분할합니다.
    *   **청킹 전략:** 청크의 크기와 분할 방식은 RAG 성능에 직접적인 영향을 미칩니다.
        *   **Fixed-size Chunking:** 고정된 크기로 텍스트를 자릅니다. 가장 간단하지만, 문장의 의미가 중간에 잘릴 위험이 있습니다.
        *   **Recursive Character Text Splitting:** 재귀적으로 문단을 나누고, 문장을 나누는 방식으로 의미 경계를 최대한 존중하며 분할합니다.
        *   **Semantic Chunking:** 임베딩 모델을 사용하여 의미적으로 유사한 문장들을 하나의 청크로 묶습니다. 가장 진보된 방식입니다.
3.  **임베딩 (Embedding):** 각 텍스트 청크를 `[0.7, -0.2, 0.5, ...]` 와 같은 숫자 벡터(Vector)로 변환합니다. 이 벡터는 '의미의 지도'에서 해당 단락의 위치 좌표와 같습니다. "강아지"와 "멍멍이"는 지도에서 매우 가까운 곳에 위치하게 됩니다.
    *   **대표적인 임베딩 모델:** `OpenAI text-embedding-3-small`, `BGE-M3`, `Ko-SimCSE-roberta` 등
4.  **저장 (Store):** 임베딩된 벡터와 원본 텍스트 청크를 **벡터 데이터베이스(Vector Database)**에 저장합니다. 이 DB는 특정 '의미 좌표'와 가장 가까운 좌표들을 초고속으로 찾아주는 역할을 합니다.
    *   **대표적인 벡터 DB:** `FAISS`, `ChromaDB`, `Pinecone`, `Weaviate`

#### 2단계: 검색 및 생성 (질문에 맞는 책 찾아 답변)

사용자의 질문이 들어왔을 때, 준비된 지식 창고를 참조하여 최종 답변을 생성하는 과정입니다.

1.  **사용자 질문 임베딩 (Embed Query):** 사용자의 질문("에펠탑은 누가 설계했어?") 또한 벡터로 변환하여 '의미의 좌표'를 찾습니다.
2.  **유사도 검색 (Similarity Search):** 질문의 좌표와 가장 가까운 거리에 있는 문서 단락 벡터들을 도서관에서 K개(예: 5개) 찾아냅니다.
3.  **프롬프트 구성 (Prompt Construction):** 검색된 K개의 텍스트 청크(Context)를 사용자의 원본 질문과 함께 LLM에게 전달할 프롬프트에 포함시킵니다.
4.  **답변 생성 (Generation):** LLM은 구성된 프롬프트를 바탕으로, 주어진 컨텍스트 정보에 근거하여 질문에 대한 최종 답변을 생성합니다.

#### [심화] RAG 검색 성능 고도화 기법

*   **하이브리드 검색 (Hybrid Search):** 의미 기반의 벡터 검색과 키워드 기반의 전통적인 검색(예: BM25)을 결합하여, 의미의 유사성과 키워드의 정확성을 모두 잡는 방식입니다.
*   **재정렬 (Re-ranking):** 1차적으로 검색된 후보들을 더 정교한 모델(Cross-encoder 등)로 다시 평가하여, 질문과 가장 관련성 높은 순서로 재정렬합니다. 이는 LLM이 더 중요한 정보를 먼저 보도록 하여 답변의 질을 높입니다.

---

## 1.2 AI 에이전트: 스스로 일하는 '디지털 비서'

RAG가 AI를 더 정확하게 만든다면, **AI 에이전트**는 AI를 더 **자율적이고 능동적**으로 만듭니다. 에이전트는 단순히 질문에 답하는 것을 넘어, **목표를 주면 스스로 계획을 세우고, 필요한 도구를 사용하며, 문제를 해결**하는 '디지털 비서'와 같습니다.

### AI 에이전트의 핵심 구성 요소

AI 에이전트는 특정 목표를 달성하기 위해 자율적으로 행동하는 시스템으로, 크게 4가지 핵심 요소로 구성됩니다.

1.  **LLM (The Brain):** 에이전트의 핵심 두뇌 역할을 하는 대규모 언어 모델입니다. 모든 추론, 계획, 의사결정의 중심입니다.
2.  **계획 (Planning):** 사용자의 복잡한 목표를 달성 가능한 작은 하위 작업들로 분해하고, 전체적인 실행 계획을 수립합니다.
    *   **예시:** "최근 일주일간의 AI 뉴스 요약 보고서 작성"이라는 목표를 받으면, 에이전트는 `1. 'AI 뉴스' 키워드로 웹 검색 -> 2. 검색 결과에서 신뢰할 수 있는 기사 선택 -> 3. 각 기사 내용 요약 -> 4. 전체 내용을 취합하여 보고서 형태로 작성` 과 같이 계획을 수립합니다.
3.  **기억 (Memory):** 과거의 행동과 그 결과를 기억하여 현재의 의사결정에 활용합니다.
    *   **단기 기억 (Short-term Memory):** 현재 대화나 작업의 컨텍스트를 유지합니다. (예: 방금 사용한 도구의 결과)
    *   **장기 기억 (Long-term Memory):** 과거의 경험, 성공/실패 사례 등을 장기적으로 저장하여 미래의 행동을 최적화합니다. (RAG의 벡터 DB가 장기 기억의 한 형태로 활용될 수 있습니다.)
4.  **도구 사용 (Tool Use):** LLM 자체의 한계를 극복하기 위해 외부 도구(API)를 호출하여 정보를 얻거나 특정 작업을 수행합니다.
    *   **예시 도구:** 웹 검색 API, 계산기 API, 코드 실행기, 데이터베이스 조회 API, RAG 시스템 등

### 에이전트의 작동 매커니즘: ReAct 프레임워크

에이전트는 **ReAct (Reason + Act)** 라는 원칙에 따라 **"생각 -> 행동 -> 관찰"** 사이클을 반복하며 목표를 향해 나아갑니다.

*   **상황:** "파리 날씨를 보고, 날씨에 맞는 옷차림을 추천해줘." 라는 목표 부여.

1.  **생각 (Thought):** "사용자가 두 가지를 원하네. 첫째, 파리의 현재 날씨. 둘째, 옷차림 추천. 먼저 날씨부터 알아봐야겠다. '웹 검색' 도구가 가장 좋겠어."
2.  **행동 (Action):** `웹 검색('파리 현재 날씨')` 라는 도구를 사용한다.
3.  **관찰 (Observation):** "검색 결과: '파리 현재 기온 15도, 강수 확률 80%'. 아, 춥고 비가 오는구나."
4.  **생각 (Thought):** "날씨를 확인했으니 이제 옷차림을 추천해야지. 15도에 비가 오면 쌀쌀하니까 재킷이 좋겠고, 우산도 필수겠네."
5.  **행동 (Action):** 사용자에게 최종 답변을 생성한다: "현재 파리 날씨는 15도에 비가 오고 있습니다. 쌀쌀할 수 있으니 가벼운 재킷과 우산을 챙기시는 걸 추천합니다."

---

## 1.3 Agentic RAG: '일 잘하는 비서'에게 '오픈북'을 쥐여주다

**Agentic RAG**는 '스스로 일하는 디지털 비서'(AI 에이전트)에게 '오픈북 시험 능력'(RAG)을 부여한 것입니다. 즉, **RAG가 에이전트가 사용할 수 있는 여러 도구 중 하나**가 되는, 훨씬 더 강력하고 유연한 패러다임입니다.

### 기존 RAG vs Agentic RAG: 한눈에 보기

| 구분 | 기존 RAG (Standard RAG) | Agentic RAG |
| :--- | :--- | :--- |
| **워크플로우** | **정적 (Static)**: `검색 -> 생성`의 단방향 파이프라인 | **동적 (Dynamic)**: `생각-행동-관찰` 루프를 통한 반복적, 순환적 작업 |
| **정보 소스** | **제한적**: 미리 정의된 단일 DB에 의존 | **확장 가능**: 웹 검색, DB, API 등 다양한 도구를 동적으로 활용 |
| **검색 방식** | **수동적**: 사용자의 초기 질문을 그대로 사용 | **능동적**: 스스로 질문을 분석, 정제, 분해하여 최적의 검색 쿼리 생성 |
| **RAG의 역할** | 시스템의 핵심 프로세스 | 에이전트가 사용하는 **여러 도구 중 하나** |

### Agentic RAG는 어떻게 더 똑똑하게 작동하는가?

*   **상황:** "지난 분기 우리 회사 매출 올랐어? 가장 큰 원인은 뭐야?"

*   **일반 RAG의 한계:** '지난 분기 매출'을 검색해서 보고서를 찾고 "매출 15% 상승"이라고 답할 수는 있지만, '원인'을 찾기 위해 추가적인 검색이나 추론을 하지는 못합니다.

*   **Agentic RAG의 해결 과정:**
    1.  **생각:** "사용자가 '매출 실적'과 '원인' 두 가지를 궁금해하네. 먼저 사내 DB에서 매출 보고서를 찾아야겠다. **'회사_DB_검색(RAG)'** 도구를 써야지."
    2.  **행동:** `회사_DB_검색(query='2024년 4분기 매출 보고서')`
    3.  **관찰:** "결과: '4분기 매출 15% 상승. 주요 요인: 연말 프로모션 성공.'"
    4.  **생각:** "매출이 오른 건 확인했고, 원인이 '연말 프로모션'이라고 나오네. 더 구체적인 정보를 줘야겠다. 이번엔 '연말 프로모션 결과 보고서'를 찾아보자. 다시 **'회사_DB_검색(RAG)'** 도구를 써야겠다."
    5.  **행동:** `회사_DB_검색(query='연말 프로모션 결과 보고서')`
    6.  **관찰:** "결과: '홀리데이 에디션 판매량 50% 증가, 신규 가입자 30% 증가.'"
    7.  **생각:** "이제 모든 정보가 모였다. 이걸 종합해서 최종 답변을 만들자."
    8.  **행동 (최종 답변):** "네, 지난 분기 매출은 15% 상승했습니다. 가장 큰 원인은 '연말 프로모션'의 성공으로, 홀리데이 에디션 판매량이 50% 늘고 신규 가입자가 30% 증가하는 성과를 거두었습니다."

---

## 1.4 Multi-Agent: '어벤져스 팀'처럼 협력하는 AI들

복잡한 프로젝트를 혼자 다 할 수 없듯, AI도 여러 전문가가 팀을 이루면 더 강력해집니다. **멀티 에이전트** 시스템은 각자 다른 전문성을 가진 AI 에이전트들이 **하나의 팀처럼 협력**하여 공동의 목표를 달성하는 구조입니다.

> **핵심 비유:**
> 환자가 병원에 오면, 접수 데스크(오케스트레이터)가 환자의 상태를 보고 내과, 외과, 영상의학과 등 적절한 전문의(전문 에이전트)에게 진료를 연결해줍니다. 각 전문의는 자신의 분야에서 진단하고, 그 결과를 종합하여 최종 처방을 내리는 것과 같습니다.

### 멀티 에이전트 시스템의 아키텍처

1.  **에이전트 오케스트레이터 (Agent Orchestrator / Router):**
    *   '프로젝트 매니저' 또는 '캡틴 아메리카'와 같은 역할. 사용자의 요청을 가장 먼저 받아, 그 의도를 분석(Intent Classification)합니다.
    *   분석된 의도에 따라 어떤 전문 에이전트에게 작업을 할당할지 결정하고, 전체 작업 흐름을 조율합니다.
2.  **전문 에이전트 (Specialist Agents):**
    *   각자 특정 분야에 특화된 기술과 도구를 가진 '어벤져스 멤버'들입니다.
    *   **예시:**
        *   **'아이언맨' (기술 분석 에이전트):** 기술 사양 분석, 벤치마크 DB 조회.
        *   **'블랙 위도우' (시장 반응 분석 에이전트):** 소셜 미디어, 뉴스 기사 등 여론 분석.
        *   **'닥터 스트레인지' (보고서 작성 에이전트):** 여러 정보를 종합하여 보고서 작성.

### 멀티 에이전트의 장점과 과제

*   **장점:**
    *   **모듈성 및 확장성:** 각 에이전트가 독립적으로 개발, 유지보수될 수 있으며, 새로운 기능이 필요할 때 해당 전문가 에이전트를 추가하기 용이합니다.
    *   **효율성:** 복잡한 작업을 병렬로 처리하여 전체 소요 시간을 단축할 수 있습니다.
    *   **전문성:** 각 에이전트가 특정 작업에 최적화되어 더 높은 품질의 결과를 도출할 수 있습니다.
*   **과제:**
    *   **복잡성 증가:** 전체 시스템의 설계와 에이전트 간의 상호작용을 관리하는 것이 복잡합니다.
    *   **통신 오버헤드:** 에이전트 간의 통신 비용이 성능에 영향을 줄 수 있습니다.
    *   **오류 전파:** 한 에이전트의 실패가 다른 에이전트나 전체 시스템에 영향을 미칠 수 있습니다.